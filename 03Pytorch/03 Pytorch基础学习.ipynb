{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一章 Introduction\n",
    "\n",
    "PyTorch 是一个开源的机器学习库，专注于提供灵活、高效的深度学习框架。它由 Facebook 的 AI 研究团队于2016年发布，目前由 PyTorch 开发者社区维护和发展。PyTorch 提供了强大的张量操作和自动求导功能，使得构建和训练深度神经网络变得非常简单和高效。\n",
    "\n",
    "以下是 PyTorch 的一些主要特点：\n",
    "\n",
    "* 动态计算图：PyTorch 使用动态计算图，这意味着计算图是在运行时被定义和构建的，而不是在编译时静态生成。这样的设计使得 PyTorch 更加灵活，允许用户使用常规的 Python 控制流、条件语句和循环，从而更自然地定义复杂的神经网络结构。\n",
    "\n",
    "* 张量操作：PyTorch 提供了丰富的张量操作，类似于 NumPy 数组操作。张量是 PyTorch 中的核心数据结构，它类似于多维数组，可以在 CPU 或 GPU 上进行并行计算，用于存储和转换数据。\n",
    "\n",
    "* 自动求导：PyTorch 支持自动求导功能，这是深度学习中的关键特性。通过将 requires_grad=True 标志设置为张量，PyTorch 将自动跟踪对该张量的所有操作，并计算梯度，以便进行反向传播和优化。这样，用户可以轻松地构建复杂的神经网络，并利用自动求导进行训练。\n",
    "\n",
    "* 神经网络模块：PyTorch 提供了 torch.nn 模块，其中包含许多预定义的层、损失函数和优化器，使得构建神经网络模型更加方便。\n",
    "\n",
    "* 分布式训练：PyTorch 支持分布式训练，允许在多个 GPU 和多台计算机上进行模型训练，加快训练速度。\n",
    "\n",
    "* 社区支持：PyTorch 拥有庞大的开发者社区，提供了大量的教程、示例代码和技术支持，使得用户可以轻松入门并解决问题。\n",
    "\n",
    "* 深度学习生态系统：PyTorch 生态系统还包括了许多扩展库和工具，如 TorchVision（用于计算机视觉）、TorchText（用于自然语言处理）、TorchAudio（用于音频处理）等，这些库提供了丰富的预训练模型和数据处理工具，帮助用户更便捷地进行各类深度学习任务。\n",
    "\n",
    "由于其灵活性、易用性和强大的功能，PyTorch 已成为深度学习领域的热门框架之一，被广泛应用于学术界和工业界的深度学习研究和实践中。无论是入门者还是专业人士，PyTorch 都提供了很好的学习和实践平台。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二章 张量数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量a显示如下： tensor([[[0.0551, 0.3858, 0.2619],\n",
      "         [0.3986, 0.6810, 0.8291]]])\n",
      "\n",
      "张量b显示如下: tensor([[[0.7428, 0.2638, 0.9347, 0.8102],\n",
      "         [0.6775, 0.0930, 0.0678, 0.4490],\n",
      "         [0.7051, 0.4559, 0.8163, 0.6793]],\n",
      "\n",
      "        [[0.8439, 0.8096, 0.9214, 0.5219],\n",
      "         [0.4334, 0.3147, 0.6836, 0.9394],\n",
      "         [0.9021, 0.8364, 0.1733, 0.9357]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(1, 2, 3)\n",
    "b = torch.rand(2, 3, 4)\n",
    "print(\"张量a显示如下：\", a)\n",
    "print()\n",
    "print(\"张量b显示如下:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size在Pytorch中通常是表达张量的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一、创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "\n",
      "tensor([5, 6, 7, 8], dtype=torch.int32)\n",
      "\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 从Python列表创建张量\n",
    "tensor1 = torch.tensor([1, 2, 3, 4])\n",
    "print(tensor1)\n",
    "print()\n",
    "# 输出：tensor([1, 2, 3, 4])\n",
    "\n",
    "# 从NumPy数组创建张量\n",
    "import numpy as np\n",
    "numpy_array = np.array([5, 6, 7, 8])\n",
    "tensor2 = torch.tensor(numpy_array)\n",
    "print(tensor2)\n",
    "print()\n",
    "# 输出：tensor([5, 6, 7, 8])\n",
    "\n",
    "# 创建全零张量和全一张量\n",
    "tensor_zeros = torch.zeros(2, 3)\n",
    "tensor_ones = torch.ones(3, 2)\n",
    "print(tensor_zeros)\n",
    "print()\n",
    "# 输出：tensor([[0., 0., 0.],\n",
    "#               [0., 0., 0.]])\n",
    "print(tensor_ones)\n",
    "# 输出：tensor([[1., 1.],\n",
    "#               [1., 1.],\n",
    "#               [1., 1.]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二、未初始化的张量\n",
    "\n",
    "未初始化的张量是在创建时没有被赋予明确初始值的张量。在创建这样的张量时，它的值将取决于内存中的内容，这些值是不确定的，并且可能包含任意数据。\n",
    "\n",
    "未初始化的张量在 PyTorch 中有一定的用途，但需要特别小心使用，因为它们的值是不可预测的。一般情况下，我们应该尽量避免使用未初始化的张量，以确保模型的稳定性和可重复性。\n",
    "\n",
    "以下是一些使用未初始化张量的情况：\n",
    "\n",
    "1. 性能优化：在某些情况下，为了提高性能，可以创建未初始化的张量，并在后续计算中立即用具体的值填充它们。这可以节省初始化的时间开销，尤其在大规模深度学习模型中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建未初始化的大小为 3x3 的张量\n",
    "tensor_uninitialized = torch.empty(3, 3)\n",
    "torch.FloatTensor(3,3)\n",
    "torch.IntTensor(3,3)\n",
    "\n",
    "# 用具体值填充张量\n",
    "tensor_uninitialized.fill_(1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然未初始化的张量在某些情况下可能带来性能优势，但使用时需要格外小心。因为其值是不确定的，可能导致计算结果出现意外的错误。在大多数情况下，我们还是建议使用经过适当初始化的张量，以确保模型的稳定性和可靠性。在神经网络训练和权重初始化等场景下，使用预定义的初始化方法能更好地保证模型的收敛和性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三、初始化张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n随机生成[0, 1]的3*3的矩阵\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3, 3)\n",
    "'''\n",
    "随机生成[0, 1]的3*3的矩阵\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randint(1, 10, [3, 3])      #第1、2个参数分别定义最小值、最大值；第三个参数则传入张量的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 6, 8],\n",
       "        [4, 5, 8],\n",
       "        [9, 8, 7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint_like(b, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 7, 7],\n",
       "        [7, 7, 7]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([2,3],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  3.3333,  6.6667, 10.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 10, steps = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(2)\n",
    "# 随机生成整数序列长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 四、张量的切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[6.1020e-01, 7.0324e-01, 7.9653e-01,  ..., 6.5924e-01,\n",
      "           6.1466e-01, 6.2970e-01],\n",
      "          [1.8842e-01, 1.4363e-01, 6.0790e-01,  ..., 7.7858e-01,\n",
      "           6.2771e-01, 8.0575e-01],\n",
      "          [9.9348e-01, 5.2393e-01, 8.3399e-01,  ..., 7.7849e-02,\n",
      "           6.9803e-01, 5.6223e-01],\n",
      "          ...,\n",
      "          [1.9943e-02, 1.3519e-01, 4.2311e-02,  ..., 9.0990e-01,\n",
      "           5.4406e-01, 3.9170e-01],\n",
      "          [1.2294e-02, 7.8378e-01, 9.7433e-01,  ..., 3.2907e-01,\n",
      "           6.6525e-02, 4.0554e-01],\n",
      "          [3.8135e-01, 4.6726e-01, 5.1262e-01,  ..., 8.0011e-01,\n",
      "           6.8014e-01, 5.9046e-01]],\n",
      "\n",
      "         [[8.4884e-01, 4.6425e-01, 8.2425e-01,  ..., 6.3643e-01,\n",
      "           4.3310e-01, 9.4725e-01],\n",
      "          [9.3304e-01, 7.2707e-01, 4.8812e-02,  ..., 4.9347e-01,\n",
      "           7.7316e-01, 9.1889e-01],\n",
      "          [3.5354e-01, 4.4210e-01, 2.0949e-01,  ..., 4.6873e-01,\n",
      "           4.8570e-01, 3.9403e-01],\n",
      "          ...,\n",
      "          [9.9303e-01, 1.9076e-01, 8.0788e-01,  ..., 6.7892e-01,\n",
      "           5.9933e-01, 3.2294e-01],\n",
      "          [2.9000e-01, 9.0661e-01, 1.9806e-01,  ..., 1.9910e-01,\n",
      "           3.6487e-01, 5.8286e-01],\n",
      "          [7.8038e-01, 3.8350e-03, 2.8600e-01,  ..., 7.4327e-01,\n",
      "           2.7207e-01, 1.1778e-01]],\n",
      "\n",
      "         [[1.9658e-01, 4.8410e-02, 1.4848e-01,  ..., 8.7631e-01,\n",
      "           9.2727e-01, 5.8059e-01],\n",
      "          [7.6819e-01, 8.5827e-01, 6.6446e-01,  ..., 9.0819e-01,\n",
      "           5.1988e-03, 5.9241e-01],\n",
      "          [5.9743e-01, 3.0876e-01, 7.9465e-01,  ..., 9.1920e-01,\n",
      "           3.9784e-01, 2.0994e-01],\n",
      "          ...,\n",
      "          [4.9105e-01, 4.7881e-01, 7.6939e-01,  ..., 6.6966e-01,\n",
      "           9.3421e-01, 9.3457e-01],\n",
      "          [8.6042e-01, 1.1985e-01, 5.8446e-01,  ..., 1.0953e-02,\n",
      "           1.2631e-01, 1.0140e-01],\n",
      "          [1.0324e-01, 6.1281e-01, 9.8946e-01,  ..., 1.6078e-01,\n",
      "           1.5585e-01, 9.4586e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.6842e-01, 5.2563e-01, 5.9803e-01,  ..., 3.5911e-01,\n",
      "           4.9597e-01, 5.7084e-01],\n",
      "          [2.6489e-01, 3.1934e-02, 4.6737e-02,  ..., 3.9925e-01,\n",
      "           3.7711e-02, 3.5355e-01],\n",
      "          [9.6135e-01, 6.5477e-01, 8.4976e-01,  ..., 4.4520e-01,\n",
      "           6.8800e-01, 5.8513e-01],\n",
      "          ...,\n",
      "          [6.0178e-02, 6.5351e-01, 9.1080e-01,  ..., 3.4099e-01,\n",
      "           5.6126e-01, 1.4052e-01],\n",
      "          [6.4121e-01, 5.7672e-01, 6.7832e-01,  ..., 9.6524e-01,\n",
      "           6.5278e-01, 2.6655e-01],\n",
      "          [8.2709e-01, 1.6804e-01, 9.1069e-01,  ..., 5.5306e-01,\n",
      "           7.6788e-01, 6.6526e-01]],\n",
      "\n",
      "         [[9.3595e-01, 7.2041e-01, 5.8574e-01,  ..., 4.8448e-01,\n",
      "           3.4453e-01, 6.7035e-01],\n",
      "          [1.3146e-01, 5.8897e-01, 5.9127e-01,  ..., 5.3081e-02,\n",
      "           1.9216e-01, 5.0945e-01],\n",
      "          [9.4952e-02, 9.4110e-02, 4.9790e-01,  ..., 4.9036e-01,\n",
      "           6.0938e-01, 1.3659e-01],\n",
      "          ...,\n",
      "          [1.3674e-01, 7.5194e-01, 7.2131e-01,  ..., 8.9090e-02,\n",
      "           5.6913e-01, 4.3252e-01],\n",
      "          [2.0330e-02, 7.9298e-01, 2.1044e-01,  ..., 8.9985e-01,\n",
      "           2.4938e-01, 8.9562e-02],\n",
      "          [8.2667e-01, 5.0137e-01, 3.5028e-01,  ..., 4.7965e-02,\n",
      "           4.0247e-01, 3.1519e-01]],\n",
      "\n",
      "         [[4.4202e-01, 7.6311e-01, 7.6084e-01,  ..., 3.9895e-01,\n",
      "           2.8944e-01, 8.6954e-01],\n",
      "          [8.3554e-01, 8.2644e-01, 4.1926e-01,  ..., 1.0525e-02,\n",
      "           2.4381e-01, 7.1944e-01],\n",
      "          [5.9439e-01, 2.3341e-01, 9.3016e-01,  ..., 5.6676e-01,\n",
      "           8.7973e-01, 6.9925e-01],\n",
      "          ...,\n",
      "          [5.3141e-02, 5.5753e-01, 5.0899e-01,  ..., 9.2774e-01,\n",
      "           3.1442e-01, 2.7258e-01],\n",
      "          [5.6996e-01, 8.5898e-01, 3.0805e-01,  ..., 9.9791e-01,\n",
      "           8.5464e-01, 3.3282e-01],\n",
      "          [1.0902e-01, 6.3013e-01, 1.7097e-01,  ..., 8.7764e-01,\n",
      "           6.6081e-01, 8.5968e-02]]],\n",
      "\n",
      "\n",
      "        [[[8.5628e-01, 7.7486e-01, 5.8062e-02,  ..., 3.0069e-01,\n",
      "           9.8543e-02, 1.4096e-01],\n",
      "          [8.3549e-01, 1.5196e-01, 6.7439e-01,  ..., 7.6082e-01,\n",
      "           2.2467e-01, 8.5376e-02],\n",
      "          [5.5915e-01, 6.1297e-02, 8.9916e-01,  ..., 1.0876e-01,\n",
      "           8.2537e-01, 5.7274e-01],\n",
      "          ...,\n",
      "          [1.1965e-01, 4.4224e-01, 8.3964e-01,  ..., 5.3137e-01,\n",
      "           5.6845e-01, 7.2634e-01],\n",
      "          [3.6179e-01, 8.3098e-01, 2.5039e-01,  ..., 8.3585e-01,\n",
      "           5.2219e-01, 1.1396e-01],\n",
      "          [1.0001e-01, 3.7378e-01, 1.9623e-01,  ..., 8.7318e-01,\n",
      "           8.9368e-01, 1.5194e-01]],\n",
      "\n",
      "         [[4.5431e-01, 2.6412e-01, 7.3732e-01,  ..., 1.2322e-01,\n",
      "           2.6893e-01, 4.6904e-01],\n",
      "          [6.9085e-01, 4.9489e-01, 5.5587e-01,  ..., 7.7818e-01,\n",
      "           3.7721e-02, 7.9807e-01],\n",
      "          [8.6322e-01, 5.0601e-01, 5.0415e-02,  ..., 5.9365e-01,\n",
      "           6.0206e-01, 5.2424e-01],\n",
      "          ...,\n",
      "          [1.0953e-01, 5.5347e-01, 3.8595e-01,  ..., 3.5433e-01,\n",
      "           2.6392e-01, 6.2637e-01],\n",
      "          [2.7382e-01, 2.0621e-01, 2.4234e-01,  ..., 6.2462e-02,\n",
      "           1.5667e-02, 1.8864e-01],\n",
      "          [6.6405e-01, 6.9327e-01, 7.4927e-01,  ..., 3.2827e-01,\n",
      "           2.0534e-01, 1.5753e-01]],\n",
      "\n",
      "         [[7.2646e-01, 1.6605e-01, 4.8638e-01,  ..., 1.5627e-01,\n",
      "           4.8876e-01, 7.7416e-01],\n",
      "          [2.5124e-01, 9.5326e-02, 7.7343e-01,  ..., 2.0414e-01,\n",
      "           6.2758e-01, 1.3056e-01],\n",
      "          [1.2046e-01, 3.1271e-01, 1.2043e-01,  ..., 7.3137e-01,\n",
      "           7.8251e-01, 6.5021e-01],\n",
      "          ...,\n",
      "          [2.5816e-01, 6.3900e-01, 2.4532e-01,  ..., 3.6040e-01,\n",
      "           2.1637e-01, 1.0360e-01],\n",
      "          [4.6894e-01, 2.4090e-01, 9.0457e-01,  ..., 5.6529e-01,\n",
      "           1.7621e-01, 7.8251e-01],\n",
      "          [7.1175e-01, 2.0031e-01, 2.0582e-01,  ..., 8.3208e-01,\n",
      "           9.1945e-01, 5.3180e-02]]],\n",
      "\n",
      "\n",
      "        [[[5.7248e-01, 7.8426e-01, 2.9390e-01,  ..., 5.2643e-01,\n",
      "           2.5763e-01, 9.8452e-01],\n",
      "          [8.4884e-01, 8.3695e-01, 2.9887e-01,  ..., 8.2070e-01,\n",
      "           5.8250e-01, 7.1508e-01],\n",
      "          [8.0492e-01, 2.3723e-01, 1.6027e-01,  ..., 4.9907e-02,\n",
      "           6.6573e-02, 4.3147e-01],\n",
      "          ...,\n",
      "          [2.6298e-02, 4.1005e-01, 4.1084e-01,  ..., 9.7673e-01,\n",
      "           2.5784e-01, 5.2879e-01],\n",
      "          [1.9996e-01, 1.6984e-01, 6.4593e-01,  ..., 8.0851e-01,\n",
      "           9.6105e-01, 7.4413e-01],\n",
      "          [1.1036e-01, 3.0522e-01, 5.2303e-01,  ..., 1.7806e-02,\n",
      "           3.5302e-01, 1.3140e-01]],\n",
      "\n",
      "         [[3.7040e-01, 9.0112e-01, 8.5412e-01,  ..., 3.5513e-01,\n",
      "           6.4161e-01, 1.3081e-01],\n",
      "          [6.2310e-01, 4.5708e-01, 2.2164e-01,  ..., 9.8968e-01,\n",
      "           1.3756e-02, 5.9440e-01],\n",
      "          [4.4892e-01, 6.9804e-01, 6.7801e-01,  ..., 3.9075e-01,\n",
      "           9.3420e-01, 7.6792e-01],\n",
      "          ...,\n",
      "          [7.3851e-01, 6.7579e-01, 3.1532e-01,  ..., 5.2936e-01,\n",
      "           9.1214e-01, 1.2427e-01],\n",
      "          [9.2675e-02, 2.2333e-01, 5.7484e-01,  ..., 6.8335e-01,\n",
      "           8.7920e-01, 5.0412e-01],\n",
      "          [3.9304e-01, 6.2102e-01, 3.2714e-01,  ..., 3.7282e-01,\n",
      "           9.2214e-01, 2.5038e-01]],\n",
      "\n",
      "         [[9.2578e-01, 5.5332e-01, 4.4492e-01,  ..., 7.8852e-01,\n",
      "           8.9222e-02, 9.7599e-01],\n",
      "          [3.4254e-01, 8.8169e-01, 6.0184e-01,  ..., 4.7003e-01,\n",
      "           6.1013e-01, 3.1195e-01],\n",
      "          [6.8004e-01, 9.1053e-01, 7.0417e-01,  ..., 3.9116e-01,\n",
      "           8.2484e-01, 4.8718e-01],\n",
      "          ...,\n",
      "          [3.0786e-01, 1.1253e-01, 4.9952e-01,  ..., 4.5720e-01,\n",
      "           6.7670e-01, 1.0866e-01],\n",
      "          [5.3214e-01, 4.6679e-01, 2.2842e-01,  ..., 6.0932e-01,\n",
      "           4.5581e-01, 2.1535e-04],\n",
      "          [3.8131e-01, 5.4269e-01, 3.1874e-01,  ..., 9.4204e-01,\n",
      "           8.0936e-01, 2.2003e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 3, 12, 23)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12, 23])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 23])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 2, 9, 2],\n",
      "        [8, 3, 9, 6],\n",
      "        [1, 8, 7, 3]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randint(1, 10, [3, 4])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 2],\n",
       "        [1, 3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[::2, ::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 2, 9, 2],\n",
       "        [8, 3, 9, 6],\n",
       "        [1, 8, 7, 3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 2, 9, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 五、维度变换\n",
    "\n",
    "* View/reshape\n",
    "* Squeeze/unsqueeze\n",
    "* Transpose/t/permute\n",
    "* Expand/repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1、Viev/ reshape函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(4, 1, 28, 28)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(4, 28*28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(4, 28*28).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 维度变换一定要有物理意义，不然不要改变，否则会污染数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2、unsqueeze函数（插入维度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1, 28, 28])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(0).shape      # 在第一个维度前插入一个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 1, 28, 28])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(1).shape      # 在第二个维度前面插入一个维度。正数参数是在前面插入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(-1).shape       # 在最后一个维度。负数参数是在后面插入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3、squeeze函数（挤压维度）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(1, 32, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 1, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4、Expand/Repeat    (扩展维度)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expand函数和repeat函数在扩展张量维度方面有一些区别。\n",
    "\n",
    "1. 维度扩展方式不同：\n",
    "- expand函数通过复制原始张量的数据来扩展维度，不会占用额外的内存。它只是通过改变张量的大小和步长来表示扩展后的张量。\n",
    "- repeat函数通过重复原始张量的数据来扩展维度，会占用额外的内存。它会创建一个新的张量，其中包含原始张量的副本。\n",
    "\n",
    "2. 对于不可扩展的维度的处理方式不同：\n",
    "- expand函数可以扩展任意维度，但是对于不可扩展的维度（即维度大小为1），它只是通过改变步长来表示扩展后的张量，而不会复制数据。\n",
    "- repeat函数可以扩展任意维度，包括不可扩展的维度。它会复制原始张量的数据来填充扩展后的维度。\n",
    "\n",
    "综上所述，expand函数适用于在不占用额外内存的情况下扩展张量的维度，而repeat函数适用于需要复制数据来扩展维度的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119]],\n",
      "\n",
      "         [[0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662]],\n",
      "\n",
      "         [[0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809]],\n",
      "\n",
      "         [[0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938]],\n",
      "\n",
      "         [[0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385]]],\n",
      "\n",
      "\n",
      "        [[[0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119]],\n",
      "\n",
      "         [[0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662]],\n",
      "\n",
      "         [[0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809]],\n",
      "\n",
      "         [[0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938]],\n",
      "\n",
      "         [[0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385]]],\n",
      "\n",
      "\n",
      "        [[[0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119]],\n",
      "\n",
      "         [[0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662]],\n",
      "\n",
      "         [[0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809]],\n",
      "\n",
      "         [[0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938]],\n",
      "\n",
      "         [[0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385]]],\n",
      "\n",
      "\n",
      "        [[[0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119],\n",
      "          [0.0119, 0.0119, 0.0119, 0.0119]],\n",
      "\n",
      "         [[0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662],\n",
      "          [0.6662, 0.6662, 0.6662, 0.6662]],\n",
      "\n",
      "         [[0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776],\n",
      "          [0.7776, 0.7776, 0.7776, 0.7776]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809],\n",
      "          [0.5809, 0.5809, 0.5809, 0.5809]],\n",
      "\n",
      "         [[0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938],\n",
      "          [0.6938, 0.6938, 0.6938, 0.6938]],\n",
      "\n",
      "         [[0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385],\n",
      "          [0.9385, 0.9385, 0.9385, 0.9385]]]])\n"
     ]
    }
   ],
   "source": [
    "print(c.expand(4, 32, 4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5、矩阵的转置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 4D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a\u001b[39m.\u001b[39;49mt()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 4D"
     ]
    }
   ],
   "source": [
    "a.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵的转置只能适用于二维数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6、Permute函数     (维度所在位置进行变化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 28, 28, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.permute(0, 2, 3, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 六、Broadcast（维度扩展）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 PyTorch 中，Broadcasting 是一种功能强大的机制，它允许在进行元素级操作时，自动地对形状不同的张量进行广播（Broadcasting）使其具有相容的形状，从而完成操作。\n",
    "\n",
    "当进行元素级操作时，如果两个张量的形状不完全相同，PyTorch 会尝试自动进行 Broadcasting，以使它们具有相容的形状。这样，你可以对形状不同的张量进行逐元素的操作，而无需手动调整它们的形状。\n",
    "\n",
    "Broadcasting 遵循一组规则，以决定如何自动调整张量的形状。以下是 Broadcasting 规则的概述：\n",
    "\n",
    "* 当两个张量的维度相同时，它们的形状必须完全相同，才能进行元素级操作。\n",
    "\n",
    "* 当两个张量的维度不同时，从尾部（末尾）开始逐一比较维度：\n",
    "\n",
    "如果两个维度相等，或者其中一个维度为 1，那么这两个维度是相容的。\n",
    "如果两个维度不相等，并且没有一个维度是 1，那么这两个张量的形状不兼容，无法进行 Broadcasting。\n",
    "当两个张量的形状不兼容时，PyTorch 将会抛出一个错误。\n",
    "\n",
    "下面是一个简单的示例来说明 Broadcasting 的用法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  6],\n",
      "        [ 8,  9],\n",
      "        [11, 12]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个形状为 (3, 1) 的张量\n",
    "a = torch.tensor([[1], [2], [3]])\n",
    "\n",
    "# 创建一个形状为 (3, 2) 的张量\n",
    "b = torch.tensor([[4, 5], [6, 7], [8, 9]])\n",
    "\n",
    "# 使用 Broadcasting，将 a 和 b 相加\n",
    "result = a + b\n",
    "\n",
    "print(result)\n",
    "# 输出结果:\n",
    "# tensor([[ 5,  6],\n",
    "#         [ 8,  9],\n",
    "#         [11, 12]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 七、合并与分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(5, 32, 8)\n",
    "b = torch.rand(5, 32, 8)\n",
    "\n",
    "torch.cat([a, b], dim= 0).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of tensors must match except in dimension of which to be cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b], dim= 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 32, 2, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a, b], dim=2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于Stack来说，来个合并的张量必须保持一致。而且在合并后会产生一个新的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split： by len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "[aa, bb, cc, dd, ee] = a.split(1, dim= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk: by num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = a.chunk(5, dim= 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 八、数学运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2575, 0.8721, 0.4041, 1.2362],\n",
       "        [1.5017, 1.1262, 1.1620, 0.9128],\n",
       "        [1.5665, 1.0487, 0.7362, 0.5525]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3, 4)\n",
    "b = torch.rand(4)\n",
    "torch.add(a, b)         # 张量的加法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4052,  0.2345, -0.2630,  0.1699],\n",
       "        [-0.1610,  0.4886,  0.4949, -0.1534],\n",
       "        [-0.0963,  0.4112,  0.0692, -0.5137]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(a, b)         # 张量的减法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3543, 0.1764, 0.0235, 0.3748],\n",
       "        [0.5573, 0.2574, 0.2763, 0.2024],\n",
       "        [0.6112, 0.2327, 0.1343, 0.0103]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(a, b)         # 张量的乘法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5126, 1.7358, 0.2116, 1.3187],\n",
       "        [0.8063, 2.5327, 2.4840, 0.7123],\n",
       "        [0.8842, 2.2898, 1.2074, 0.0363]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(a, b)         # 张量的除法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 15., 18.],\n",
       "        [12., 15., 18.],\n",
       "        [12., 15., 18.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 3)\n",
    "b = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
    "torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.,  9.],\n",
       "        [16., 25., 36.],\n",
       "        [49., 64., 81.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(b, 2)           # 次方运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7183, 2.7183, 2.7183],\n",
       "        [2.7183, 2.7183, 2.7183],\n",
       "        [2.7183, 2.7183, 2.7183]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 九、属性统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.), tensor(8.), tensor(8.))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.full([8], 1, dtype=torch.float)\n",
    "b = a.view(2, 4)\n",
    "c = a.view(2, 2, 2)\n",
    "a.norm(1), b.norm(1), c.norm(1)                 # 求范数，1范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(a.max())          # 求最大值\n",
    "print(a.min())          # 求最小值\n",
    "print(a.mean())         # 求平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
