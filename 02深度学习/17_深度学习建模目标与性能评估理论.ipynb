{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. 深度学习建模目标与性能评估理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1 机器学习目标与模型评估方法\n",
    "\n",
    "在了解深度学习基本模型的概念与实现方法后，接下来，我们将详细探讨深度学习模型优化的常用方法。从上一课的实验中不难发现，要把一个模型‘建好’已是不易，而要想办法把模型的效果进行提升，如果没有基础理论支持和方法论工具，优化过程无异于盲人摸象。因此，本节课从建模的根本目标出发，围绕模型优化的基本概念和核心理论进行全面梳理，并在此基础之上介绍相关实践方法，逐渐拨开模型优化面前的迷雾。\n",
    "\n",
    "我们经常会对模型的好坏优劣进行评估，Lesson 12中我们也使用了准确率，MSE等指标评估模型结果，看起来模型评估是围绕某项指标在进行评估，指标好模型就好，指标不好，模型就不好，其实并不完全如此。要了解模型的性能其实并不简单，固然我们会使用某些指标去进行评估，但其实指标也只是我们了解模型性能的途径而不是模型性能本身。而要真实，深刻的评判模型性能，就必须首先了解机器学习的建模目标，并在此基础之上熟悉我们判断模型是否能够完成目标的一些方法，当然，只有真实了解模型性能，我们才能进一步考虑如何提升模型性能。因此，在正式讲解模型优化方法之前，我们需要花些时间讨论机器学习算法的建模目标，机器学习算法为了能够达到目标的一般思路，以及评估模型性能的手段，也就是模型评估指标。\n",
    "\n",
    "无论是机器学习还是传统的统计分析模型，核心使命就是探索数字规律，而有监督学习则是希望在探索数字规律的基础上进一步对未来进行预测，当然，在数字的世界，这个预测未来，也就是预测未来某项事件的某项数值指标，如某地区未来患病人次，具备某种数字特征的图片上的动物是哪一类，此处的未来也并非指的是绝对意义上的以后的时间，而是模型训练暂时未接触到的数据。正是因为模型有了在未知标签情况下进行预判的能力，有监督学习才有了存在的价值，但我们知道，基本上所有的模型，都只能从以往的历史经验当中进行学习，也就是在以往的，已经知道的数据集上进行训练，怎么证明能够在接下来的数据中也具有一定的预测能力呢？或者说，要怎么训练模型，才能让模型在未知的数据集上也拥有良好的表现呢？\n",
    "\n",
    "目的相同，但在具体的实现方法上，传统的统计分析建模和机器学习采用了不同的解决方案。\n",
    "\n",
    "首先，在统计分析领域，我们会假设现在的数据和未来的数据其实都属于某个存在但不可获得的总体，也就是说，现在和未来的数据都是从某个总体中抽样而来的，都是这个总体的样本。而正是因为这些数据属于同一个总体，因此具备某些相同的规律，而现在挖掘到的数据规律也就在某些程度上可以应用到未来的数据当中去，不过呢，不同抽样的样本之间也会有个体之间的区别，另外模型本身也无法完全捕获规律，而这些就是误差的来源。\n",
    "\n",
    "虽然样本和总体的概念是统计学的概念，但样本和总体的概念所假设的前后数据的“局部规律一致性‘，却是所有机器学习建模的基础。试想一下，如果获取到的数据前后描绘的不是一件事情，那么模型训练也就毫无价值。因此，无论是机器学习所强调的从业务角度出发，要确保前后数据描述的一致性，还是统计分析所强调的样本和总体的概念，都是建模的基础。\n",
    "\n",
    "在有了假设基础之后，统计分析就会利用一系列的数学方法和数理统计工具取推导总体的基本规律，也就是变量的分布规律和一些统计量的取值，由于这个过程是通过已知的样本去推断未知的总体，因此会有大量的’估计‘和’检验‘，在确定了总体的基本分布之后，才能进一步使用统计分析模型构建模型。当然，这些模型都是在总体规律基础之上，根据样本具体的数值进行的建模，我们自然有理由相信这些模型对接下来仍然是从总体中抽样而来的样本还是会具备一定的预测能力，这也就是我们对统计分析模型’信心‘的来源。简单来说，就是我们通过样本推断总体的规律，然后结合总体的规律和样本的数值构建模型，由于模型也描绘了总体规律，所以模型对接下来从总体当中抽样而来的数据也会有不错的预测效果，这个过程我们可以通过如下图进行表示：\n",
    "\n",
    "![Alt text](image-29.png)\n",
    "\n",
    "而对于机器学习来说，并没有借助‘样本-总体’的基本理论，而是简单的采用了一种后验方法；来判别模型有效性，前面说到，我们假设前后获取的数据拥有规律一致性，但数据彼此之间又略有不同，为了能够在捕捉规律的同时又考虑到‘略有不同’所带来的误差，机器学习会把当前能获取到的数据分成训练集和测试集，在训练集上构建模型，然后带入测试集的数据，观测在测试集上模型预测结果和真实结果之间的差异。这个过程其实就是在模拟获取到真实数据之后模型预测的情况，此前说到，模型能在未知标签的数据集上进行预测，就是模型的核心价值，此时的测试集就是用于模拟未来的未知标签数据集。如果模型在测试集上有不错的预测效果，我们就‘简单粗暴’的认为模型可以在真实的未来获取的未知数据集上有不错的表现。其一般过程可以由如下图表示：\n",
    "\n",
    "![Alt text](image-30.png)\n",
    "\n",
    "虽然对比数理统计分析，机器学习的证明模型有效性的过程更加简单，毕竟只要一次模拟成功，我们就认为模型对未来的数据也拥有判别效力，但这种简单的处理方式却非常实用，可以说，这是一种经过长期实践被证明行之有效的方法。这也是为什么机器学习很多时候也被认为是实证类的方法，而在以后的学习中，我们也将了解到，机器学习有很多方法都是‘经验总结的结果’。相比数理统计分析，确实没有那么严谨，但更易于理解的理论和更通用的方法，却使得机器学习可以在更为广泛的应用场景中发挥作用。\n",
    "\n",
    "据此，我们称模型在训练集上误差称为训练误差，而在测试集上的误差称为泛化误差，不过毕竟在测试集上进行测试还只是模拟演习，我们采用模型的泛化能力来描述在未知数据上的判断能力，当然泛化能力无法准确衡量，我们只能通过模型在训练集和测试集上的表现，判别模型泛化能力，当然，就像此前所说的一样，最基本的，我们会通过模型在测试集上的表现来判断模型的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.2 手动实现训练集和测试集的切分\n",
    "\n",
    "接下来，我们开始实践模型评估过程，首先是对训练集和测试集的划分，我们尝试创建一个切分训练集和测试集的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机模块\n",
    "import random\n",
    "\n",
    "# 绘图模块\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchLearning import *\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 一个cell输出多个结果\n",
    "writer = SummaryWriter(log_dir= 'reg_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(features, labels, rate = 0.7):\n",
    "    \"\"\" 训练集和测试集切分函数\n",
    "    \n",
    "    param features: 输入的特征张量\n",
    "    param labels: 输入的标签张量\n",
    "    param rate: 训练集占所有数据的比例\n",
    "    return Xtrain, Xtest, ytrain, ytest: 返回特征张量的训练集/测试集，以及标签张量的训练集，测试集\n",
    "\n",
    "    \"\"\"\n",
    "    num_examples = len(features)        # 总数据量\n",
    "    indices = list(range(num_examples)) # 数据集行索引\n",
    "    random.shuffle(indices)             # 乱序调整\n",
    "    num_train = int(num_examples * rate)    # 训练集数量\n",
    "    indices_train = torch.tensor(indices[: num_train])  # 在已经乱序的indices中挑出前num_train数量的行索引值\n",
    "    indices_test = torch.tensor(indices[num_train: ])\n",
    "    Xtrain = features[indices_train]        # 训练集特征\n",
    "    ytrain = labels[indices_train]          # 训练集标签\n",
    "    Xtest = features[indices_test]          # 测试集特征\n",
    "    ytest = labels[indices_test]            # 测试集标签\n",
    "    return Xtrain,Xtest,ytrain,ytest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，训练集和测试集可以按照 8：2或 7：3比例进行划分。在进行数据划分的过程中，如果测试集数据划分数据过多，参与模型训练的数据就会相应减少，而训练数据不足则会导致模型无法正常训练，损失函数无法收敛，模型过拟合等问题，但如果反过来测试集划分数据过少，则无法代表一般数据情况测试模型是否对未知数据也有很好的预测作用。因此，根据经验，我们一般来说会按照 8：2或者 7：3 比例进行划分。\n",
    "\n",
    "看到这里，相信肯定有小伙伴觉得根据所谓的‘经验’来定数据集划分比例不太严谨，有没有一种方法能够‘精准’的确定什么划分比例最佳呢?例如通过类似最小二乘法或者剃度下降这类优化算法来计算划分比例？各位同学可以尝试着进行思考，并给出自己的答案，课程中将在下一节介绍参数和超参数时给出详细解答。\n",
    "\n",
    "值得一提的是，在机器学习领域，充斥着大量的‘经验之谈’或者‘约定俗成’的规则，一方面这些经验为建模提供了诸多便捷，也节省了很多算力，但另一方面，通过经验来决定影响模型效果的一些‘超参数’取值的不严谨的做法，也被数理统计分析流派所诟病。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，测试函数性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.arange(10)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.arange(1, 11)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 3, 2, 7, 8, 5, 9]),\n",
       " tensor([6, 0, 1]),\n",
       " tensor([ 5,  4,  3,  8,  9,  6, 10]),\n",
       " tensor([7, 1, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split(f, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，还是在上一节课的内容上，尝试带入训练集进行建模，利用测试集评估模型建模效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "torch.manual_seed(420)\n",
    "\n",
    "# 生成回归类数据集\n",
    "features, labels = tensorGenReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0070,  0.5044,  1.0000],\n",
       "        [ 0.6704, -0.3829,  1.0000],\n",
       "        [ 0.0302,  0.3826,  1.0000],\n",
       "        ...,\n",
       "        [-0.9164, -0.6087,  1.0000],\n",
       "        [ 0.7815,  1.2865,  1.0000],\n",
       "        [ 1.4819,  1.1390,  1.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr):\n",
    "    params.data -= lr * params.grad\n",
    "    params.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(x, w):\n",
    "    return torch.mm(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):\n",
    "    num_ = y.numel()\n",
    "    sse = torch.sum((y_hat.reshape(-1, 1) - y.reshape(-1, 1)) ** 2)\n",
    "    return sse/num_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "\n",
    "# 初始化数据\n",
    "features, labels = tensorGenReg()\n",
    "\n",
    "# 切分训练集和测试集\n",
    "Xtrain, Xtest, ytrain, ytest = data_split(features, labels)\n",
    "\n",
    "# 初始化核心参数\n",
    "batch_size = 10     # 小批的数量\n",
    "lr = 0.03           # 学习率\n",
    "num_epochs = 5      # 训练过程遍历几次数据\n",
    "w = torch.zeros(3, 1, requires_grad= True)\n",
    "\n",
    "# 参与训练的模型方程\n",
    "net = linreg        # 使用回归方程\n",
    "# loss = squared_loss     # 均方误差的一半作为损失函数\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# 模型训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, Xtrain, ytrain):\n",
    "        l = loss(net(X, w), y)\n",
    "        l.backward()\n",
    "        sgd(w, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9999],\n",
       "        [-0.9994],\n",
       "        [-1.0002]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(torch.mm(Xtrain, w), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(torch.mm(Xtest, w), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们就完成了一整个从数据集划分，到训练集训练，再到测试集上测试模型性能的整个流程."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.3 Dataset和DataLoader基本使用方法于数据集切分函数\n",
    "\n",
    "接下来，我们尝试使用PyTorch原生库来实现上述功能，不过这个实现过程略显复杂，首先我们需要了解Dataset和DataLoader的基本使用方法。\n",
    "\n",
    "### 13.1.3.1 Dataset和DataLoader的基本使用方法\n",
    "\n",
    "* random_split随机切分函数\n",
    "\n",
    "首先，再PyTorch的torch.utils.data中，提供了random_split函数可用于数据集切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单测试函数功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(12).reshape(4, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x7f3cd2d9cb50>,\n",
       " <torch.utils.data.dataset.Subset at 0x7f3cb1b243d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_split(t, [2, 2])     # 输入切分的每部分数据集数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据生成结果可知，random_split函数其实生成了生成器切分结果的生成器，并不是和此前定义的函数一样，直接切分数据后返回。当然这也符合utils.data模块主要生成映射式和迭代对象的一般规定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_split(t, [2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用print函数查看生成器的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 10, 11]) tensor([0, 1, 2])\n",
      "tensor([3, 4, 5]) tensor([6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "for tr, te in random_split(t, [2, 2]):\n",
    "    print(tr, te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataset和DataLoader\n",
    "\n",
    "由于大多数调库建模过程中，我们都是先通过创建Dataset的子类并将数据保存为该子类类型，然后再使用DataLoader进行数据载入，因此更为通用的做法是先利用Dataset和DatasetLoader这两个类进行数据的读取，预处理和载入，然后再使用random_split函数进行切分。\n",
    "\n",
    "再次强调，Dataset类主要负责数据类的生成，再PyTorch中，所有数据集都是Dataset的子类；而DatasetLoader类则是加载模型训练的接口，二者的基本使用流程如下：\n",
    "\n",
    "![Alt text](image-31.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 创建数据类\n",
    "\n",
    "根据此前描述，PyTorch中所有数据都是Dataset的子类，换而言之就是再使用PyTorch建模训练数据时，需要创建一个和数据集对应的类来表示该数据集，此前我们使用的TensorDataset函数其实就是一个简单的类型转化函数，将数据统一转化为‘TensorDataset'类然后带入模型进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = tensorGenReg(bias= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0620,  0.9777, -0.5188],\n",
       "        [ 1.5322,  0.9412, -1.5458],\n",
       "        [-1.0757,  0.3685, -0.3861],\n",
       "        ...,\n",
       "        [-0.4219,  1.8953,  0.2729],\n",
       "        [ 1.5083,  2.4858,  1.2882],\n",
       "        [ 0.3493,  1.4100,  1.3258]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f3caeab5210>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TensorDataset(features, labels)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而 TensorDataset 其实使用面较窄，最直接的限制就是该函数只能将张量类型转化为TensorDataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m TensorDataset([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m], \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:192\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(tensors[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:192\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(tensors[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "TensorDataset([1, 2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更加通用的数据读取方法则是手动创建一个继承自torch.utils.data.dataset的数据类，用来作为当前数据的表示。例如Lesson 11中的乳腺癌数据，通过如下方式进行读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer as LBC \n",
    "data = LBC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单查看data数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data           # 返回数据集的特征数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target     # 返回数据集的标签数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.data)      # 返回数据集总个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，创建一个用于表示该数据集的Dataset的子类。在创建Dataset的子类过程中，必须要重写getitem方法和len方法，其中getitem方法返回输入索引后对应的特征和标签，而len方法则返回数据集的总数据个数。当然，在必须要进行的init初始化过程中，我们也可输入代表数据集基本属性的相关内容，包括数据集的特征，标签，大小等等，视情况而定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBCDataset(Dataset):\n",
    "    def __init__(self, data) :              # 创建该类数据时需要输入sklearn导入的数据集\n",
    "        self.features = data.data           # features属性返回数据集特征\n",
    "        self.labels = data.target           # labels属性返回数据集标签\n",
    "        self.lens = len(data.data)          # lens属性返回数据集大小\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        # 调用该方法不需要输入额外参数，方法最终返回index对应的特征和标签\n",
    "        return self.features[index, :], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 调用该方法不需要输入额外参数，方法最终返回数据集大小\n",
    "        return self.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LBC()\n",
    "LBC_data = LBCDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]),\n",
       " 0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看第三条数据\n",
    "LBC_data.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "       1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "       4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "       2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "       1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.features[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时LBC_data 已经是可以输入 DataLoader进而带入模型进行训练的数据集了，不过在此之前，我们可以使用random_split方法对其进行切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定训练集，测试集大小，此处7:3划分训练集和测试集\n",
    "num_train = int(LBC_data.lens * 0.7)\n",
    "num_test = LBC_data.lens - num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBC_train , LBC_test = random_split(LBC_data, [num_train, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    注意，此时切分的结果是一个映射式对象，只有dataset和indices两个属性，其中dataset属性用于查看原数据集对象，indices属性用于查看切分后数据集的每一条数据的index（序号）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        Subset\n",
      "\u001b[0;31mString form:\u001b[0m <torch.utils.data.dataset.Subset object at 0x7f7af89e3f50>\n",
      "\u001b[0;31mLength:\u001b[0m      398\n",
      "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "Subset of a dataset at specified indices.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): The whole Dataset\n",
      "    indices (sequence): Indices in the whole set selected for subset"
     ]
    }
   ],
   "source": [
    "LBC_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LBCDataset at 0x7f7af7ec6510>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过切分结果还原原始数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.dataset == LBC_data       # 还原原数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在原始数据集中查找切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384, 475, 64, 490, 496, 136, 123, 300, 175, 342]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train.indices[:10]      # 抽取的训练集的index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，无论时迭代式还是映射式生成数据，都可以使用print查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.328e+01, 1.372e+01, 8.579e+01, 5.418e+02, 8.363e-02, 8.575e-02,\n",
      "       5.077e-02, 2.864e-02, 1.617e-01, 5.594e-02, 1.833e-01, 5.308e-01,\n",
      "       1.592e+00, 1.526e+01, 4.271e-03, 2.073e-02, 2.828e-02, 8.468e-03,\n",
      "       1.461e-02, 2.613e-03, 1.424e+01, 1.737e+01, 9.659e+01, 6.237e+02,\n",
      "       1.166e-01, 2.685e-01, 2.866e-01, 9.173e-02, 2.736e-01, 7.320e-02]), 1)\n"
     ]
    }
   ],
   "source": [
    "for i in LBC_train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.328e+01, 1.372e+01, 8.579e+01, 5.418e+02, 8.363e-02, 8.575e-02,\n",
       "        5.077e-02, 2.864e-02, 1.617e-01, 5.594e-02, 1.833e-01, 5.308e-01,\n",
       "        1.592e+00, 1.526e+01, 4.271e-03, 2.073e-02, 2.828e-02, 8.468e-03,\n",
       "        1.461e-02, 2.613e-03, 1.424e+01, 1.737e+01, 9.659e+01, 6.237e+02,\n",
       "        1.166e-01, 2.685e-01, 2.866e-01, 9.173e-02, 2.736e-01, 7.320e-02]),\n",
       " 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_data.__getitem__(384)           # 验证是否是LBC_train的第一条数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    还是需要强调，虽然PyTorch的数据表示形式会略显复杂，但这是应对复杂大规模数据计算之必须，面对海量，非结构化数据，我们很难取查看一条条数据，而只能通过一些数据集的特性来探索数据信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后使用DataLoader函数进行数据转化，由一般数据状态转化为‘可建模’的状态，所谓‘可建模’状态，指的是经过DataLoader处理的数据，不仅包含数据原始的数据信息，还包含数据处理方法信息，如调用几个线程进行训练，分多少批次等，DataLoader常用的参数如下：\n",
    "\n",
    "* batch_size: 每次迭代输入多少数据，如果是小批量梯度下降，则输入的数据量就是小批量迭代过程中‘小批’的数量\n",
    "* shuffle: 是否需要县打乱顺序然后再进行小批量的划分，一般训练集需要乱序，而测试集乱序则没有意义\n",
    "* num_worker： 启动多少线程进行计算\n",
    "\n",
    "其他更多参数，将随着我们介绍的深入逐步进行介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mT_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      "the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (Callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        `base_seed` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default value depends\n",
      "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      "        Otherwise if value of num_workers>0 default is ``2``).\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the data loader will copy Tensors\n",
      "        into device pinned memory before returning them if pin_memory is set to true.\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(LBC_train, batch_size = 10, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(LBC_test, batch_size= 10, shuffle= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    此处需要注意，对于测试集来说，数据装载并不是一定要进行的，如果测试集只是用于检测模型效果，有时可以不用装载直接带入计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，经过DataLoader处理后的数据也可以使用dataset属性查看原数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f7af89e3f50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f7af89e3f50>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset == LBC_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    这里值得一提的是，市面上有很多教材再介绍PyTorch深度学习建模过程中的数据集划分过程，会推荐使用scikit-learn中的train_test_split函数。该函数是可以非常便捷的完成数据集切分，但这种做法只能用于单机运行的数据，并且切分之后还要调用Dataset，DataLoader模块进行数据封装和加载，切分过程看似简单，但其实会额外占用非常多的存储空间和计算资源，当进行超大规模数据训练时，所造成的影响会非常明显（当然，也有可能由于数据规模过大，本地无法运行）。因此，为了更好的适应深度学习的真实应用场景，在使用数据切分等常用函数时，函数使用优先级是：\n",
    "\n",
    "    Python原生函数和类 > 依据张量及其他常用方法手动创建的函数 > SCIKIT-LEARN函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1.3.2 建模及评估过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们尝试通过调用库实现完整的数据切分，训练，查看建模结果一整个流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 数据准备过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据\n",
    "features, labels = tensorGenReg()       \n",
    "features = features[:, :-1]          # 删除最后全是1的列\n",
    "\n",
    "# 创建一个针对手动创建数据的数据类\n",
    "class GenData(Dataset):\n",
    "    def __init__(self, features, labels) :      # 创建该类时需要输入的数据集\n",
    "        self.features = features                # features属性返回数据集特征\n",
    "        self.labels = labels                    # labels 属性返回数据集标签\n",
    "        self.lens = len(features)               # lens属性返回数据集大小\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        # 调用该方法时需要输入 index数值，方法最终返回index对应的特征和标签\n",
    "        return self.features[index, :], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "         # 调用该方法不需要输入额外参数，方法最终返回数据集大小\n",
    "        return self.lens\n",
    "\n",
    "# 实例化对象\n",
    "data = GenData(features, labels)\n",
    "\n",
    "# 切分数据集\n",
    "num_train = int(data.lens * 0.7)\n",
    "num_test = data.lens - num_train\n",
    "data_train, data_test = random_split(data, [num_train, num_test])\n",
    "\n",
    "# 加载数据\n",
    "train_loader = DataLoader(data_train, batch_size= 10, shuffle= True)\n",
    "test_loader = DataLoader(data_test, batch_size= 10, shuffle= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化核心参数\n",
    "batch_size = 10         # 小批的数量\n",
    "lr = 0.03               # 学习率\n",
    "num_epochs = 3          # 训练过程遍历多少次数据\n",
    "\n",
    "# Stage 1. 定义模型\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, in_features = 2, out_features = 1) :\n",
    "        super(LR, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "# 实例化模型\n",
    "LR_model = LR()\n",
    "\n",
    "# Stage 2. 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Stage 3. 定义优化方法\n",
    "optimizer = optim.SGD(LR_model.parameters(), lr= 0.03)\n",
    "\n",
    "# Stage 4. 模型训练与测试\n",
    "def fit(net, criterion, optimizer, batchdata, epochs = 3):\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in batchdata:\n",
    "            yhat = net.forward(X)\n",
    "            loss = criterion(yhat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 模型训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(net = LR_model,\n",
    "    criterion= criterion,\n",
    "    optimizer= optimizer,\n",
    "    batchdata= train_loader,\n",
    "    epochs= num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR(\n",
       "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看训练模型\n",
    "LR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.9995, -0.9992]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.0011], requires_grad=True)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看模型参数\n",
    "list(LR_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看模型在训练集上表现，首先我们可以通过dataset和indices方法还原训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[280,\n",
       " 30,\n",
       " 21,\n",
       " 83,\n",
       " 703,\n",
       " 534,\n",
       " 711,\n",
       " 211,\n",
       " 526,\n",
       " 292,\n",
       " 510,\n",
       " 851,\n",
       " 330,\n",
       " 188,\n",
       " 192,\n",
       " 352,\n",
       " 531,\n",
       " 464,\n",
       " 737,\n",
       " 653,\n",
       " 810,\n",
       " 48,\n",
       " 708,\n",
       " 406,\n",
       " 550,\n",
       " 508,\n",
       " 363,\n",
       " 378,\n",
       " 926,\n",
       " 927,\n",
       " 492,\n",
       " 951,\n",
       " 786,\n",
       " 432,\n",
       " 108,\n",
       " 437,\n",
       " 953,\n",
       " 497,\n",
       " 86,\n",
       " 811,\n",
       " 636,\n",
       " 808,\n",
       " 39,\n",
       " 345,\n",
       " 871,\n",
       " 888,\n",
       " 293,\n",
       " 724,\n",
       " 265,\n",
       " 750,\n",
       " 583,\n",
       " 117,\n",
       " 907,\n",
       " 875,\n",
       " 614,\n",
       " 807,\n",
       " 778,\n",
       " 309,\n",
       " 358,\n",
       " 142,\n",
       " 254,\n",
       " 710,\n",
       " 852,\n",
       " 967,\n",
       " 77,\n",
       " 642,\n",
       " 463,\n",
       " 181,\n",
       " 683,\n",
       " 992,\n",
       " 109,\n",
       " 43,\n",
       " 129,\n",
       " 72,\n",
       " 78,\n",
       " 56,\n",
       " 524,\n",
       " 824,\n",
       " 873,\n",
       " 362,\n",
       " 357,\n",
       " 168,\n",
       " 333,\n",
       " 97,\n",
       " 582,\n",
       " 379,\n",
       " 678,\n",
       " 202,\n",
       " 854,\n",
       " 445,\n",
       " 8,\n",
       " 365,\n",
       " 470,\n",
       " 9,\n",
       " 968,\n",
       " 29,\n",
       " 47,\n",
       " 881,\n",
       " 984,\n",
       " 981,\n",
       " 301,\n",
       " 187,\n",
       " 858,\n",
       " 23,\n",
       " 864,\n",
       " 69,\n",
       " 922,\n",
       " 743,\n",
       " 870,\n",
       " 494,\n",
       " 113,\n",
       " 409,\n",
       " 134,\n",
       " 186,\n",
       " 832,\n",
       " 124,\n",
       " 867,\n",
       " 350,\n",
       " 698,\n",
       " 319,\n",
       " 598,\n",
       " 628,\n",
       " 179,\n",
       " 411,\n",
       " 664,\n",
       " 579,\n",
       " 641,\n",
       " 523,\n",
       " 722,\n",
       " 941,\n",
       " 573,\n",
       " 412,\n",
       " 224,\n",
       " 151,\n",
       " 880,\n",
       " 95,\n",
       " 752,\n",
       " 483,\n",
       " 131,\n",
       " 772,\n",
       " 189,\n",
       " 751,\n",
       " 342,\n",
       " 961,\n",
       " 171,\n",
       " 417,\n",
       " 451,\n",
       " 560,\n",
       " 38,\n",
       " 781,\n",
       " 769,\n",
       " 194,\n",
       " 256,\n",
       " 127,\n",
       " 733,\n",
       " 298,\n",
       " 413,\n",
       " 121,\n",
       " 813,\n",
       " 248,\n",
       " 756,\n",
       " 34,\n",
       " 930,\n",
       " 164,\n",
       " 532,\n",
       " 237,\n",
       " 827,\n",
       " 509,\n",
       " 770,\n",
       " 934,\n",
       " 87,\n",
       " 975,\n",
       " 596,\n",
       " 487,\n",
       " 577,\n",
       " 605,\n",
       " 946,\n",
       " 60,\n",
       " 574,\n",
       " 410,\n",
       " 520,\n",
       " 916,\n",
       " 592,\n",
       " 347,\n",
       " 679,\n",
       " 70,\n",
       " 512,\n",
       " 734,\n",
       " 210,\n",
       " 178,\n",
       " 199,\n",
       " 842,\n",
       " 135,\n",
       " 46,\n",
       " 196,\n",
       " 729,\n",
       " 893,\n",
       " 911,\n",
       " 822,\n",
       " 883,\n",
       " 484,\n",
       " 986,\n",
       " 688,\n",
       " 998,\n",
       " 897,\n",
       " 33,\n",
       " 625,\n",
       " 475,\n",
       " 458,\n",
       " 114,\n",
       " 606,\n",
       " 885,\n",
       " 193,\n",
       " 49,\n",
       " 654,\n",
       " 302,\n",
       " 396,\n",
       " 766,\n",
       " 740,\n",
       " 681,\n",
       " 383,\n",
       " 22,\n",
       " 17,\n",
       " 425,\n",
       " 388,\n",
       " 586,\n",
       " 700,\n",
       " 725,\n",
       " 958,\n",
       " 818,\n",
       " 3,\n",
       " 634,\n",
       " 360,\n",
       " 308,\n",
       " 369,\n",
       " 891,\n",
       " 797,\n",
       " 597,\n",
       " 544,\n",
       " 732,\n",
       " 28,\n",
       " 311,\n",
       " 59,\n",
       " 99,\n",
       " 123,\n",
       " 830,\n",
       " 848,\n",
       " 154,\n",
       " 152,\n",
       " 741,\n",
       " 675,\n",
       " 71,\n",
       " 859,\n",
       " 6,\n",
       " 63,\n",
       " 588,\n",
       " 91,\n",
       " 132,\n",
       " 552,\n",
       " 284,\n",
       " 133,\n",
       " 318,\n",
       " 640,\n",
       " 276,\n",
       " 403,\n",
       " 777,\n",
       " 339,\n",
       " 161,\n",
       " 401,\n",
       " 632,\n",
       " 332,\n",
       " 20,\n",
       " 493,\n",
       " 233,\n",
       " 987,\n",
       " 460,\n",
       " 191,\n",
       " 407,\n",
       " 110,\n",
       " 240,\n",
       " 45,\n",
       " 130,\n",
       " 387,\n",
       " 486,\n",
       " 869,\n",
       " 692,\n",
       " 843,\n",
       " 287,\n",
       " 529,\n",
       " 74,\n",
       " 895,\n",
       " 331,\n",
       " 794,\n",
       " 791,\n",
       " 461,\n",
       " 814,\n",
       " 955,\n",
       " 310,\n",
       " 225,\n",
       " 876,\n",
       " 503,\n",
       " 983,\n",
       " 626,\n",
       " 816,\n",
       " 566,\n",
       " 24,\n",
       " 838,\n",
       " 399,\n",
       " 456,\n",
       " 627,\n",
       " 570,\n",
       " 163,\n",
       " 335,\n",
       " 989,\n",
       " 768,\n",
       " 443,\n",
       " 555,\n",
       " 385,\n",
       " 576,\n",
       " 541,\n",
       " 575,\n",
       " 67,\n",
       " 723,\n",
       " 659,\n",
       " 367,\n",
       " 73,\n",
       " 990,\n",
       " 307,\n",
       " 865,\n",
       " 748,\n",
       " 915,\n",
       " 41,\n",
       " 469,\n",
       " 849,\n",
       " 246,\n",
       " 482,\n",
       " 965,\n",
       " 75,\n",
       " 676,\n",
       " 52,\n",
       " 160,\n",
       " 565,\n",
       " 55,\n",
       " 195,\n",
       " 702,\n",
       " 408,\n",
       " 235,\n",
       " 0,\n",
       " 533,\n",
       " 15,\n",
       " 693,\n",
       " 689,\n",
       " 283,\n",
       " 746,\n",
       " 539,\n",
       " 928,\n",
       " 896,\n",
       " 667,\n",
       " 35,\n",
       " 19,\n",
       " 713,\n",
       " 528,\n",
       " 829,\n",
       " 945,\n",
       " 338,\n",
       " 419,\n",
       " 904,\n",
       " 994,\n",
       " 656,\n",
       " 172,\n",
       " 118,\n",
       " 980,\n",
       " 595,\n",
       " 273,\n",
       " 803,\n",
       " 271,\n",
       " 116,\n",
       " 479,\n",
       " 670,\n",
       " 58,\n",
       " 612,\n",
       " 643,\n",
       " 259,\n",
       " 696,\n",
       " 66,\n",
       " 88,\n",
       " 238,\n",
       " 787,\n",
       " 305,\n",
       " 581,\n",
       " 982,\n",
       " 12,\n",
       " 633,\n",
       " 183,\n",
       " 942,\n",
       " 149,\n",
       " 404,\n",
       " 313,\n",
       " 604,\n",
       " 610,\n",
       " 13,\n",
       " 471,\n",
       " 694,\n",
       " 712,\n",
       " 230,\n",
       " 890,\n",
       " 669,\n",
       " 938,\n",
       " 977,\n",
       " 156,\n",
       " 82,\n",
       " 502,\n",
       " 715,\n",
       " 674,\n",
       " 44,\n",
       " 351,\n",
       " 587,\n",
       " 913,\n",
       " 988,\n",
       " 892,\n",
       " 249,\n",
       " 361,\n",
       " 427,\n",
       " 370,\n",
       " 884,\n",
       " 4,\n",
       " 90,\n",
       " 143,\n",
       " 898,\n",
       " 393,\n",
       " 236,\n",
       " 136,\n",
       " 474,\n",
       " 758,\n",
       " 219,\n",
       " 652,\n",
       " 392,\n",
       " 329,\n",
       " 506,\n",
       " 780,\n",
       " 337,\n",
       " 215,\n",
       " 81,\n",
       " 514,\n",
       " 434,\n",
       " 101,\n",
       " 800,\n",
       " 771,\n",
       " 615,\n",
       " 294,\n",
       " 543,\n",
       " 266,\n",
       " 139,\n",
       " 173,\n",
       " 584,\n",
       " 874,\n",
       " 860,\n",
       " 120,\n",
       " 935,\n",
       " 223,\n",
       " 498,\n",
       " 315,\n",
       " 556,\n",
       " 391,\n",
       " 89,\n",
       " 820,\n",
       " 447,\n",
       " 295,\n",
       " 201,\n",
       " 2,\n",
       " 446,\n",
       " 730,\n",
       " 836,\n",
       " 220,\n",
       " 250,\n",
       " 701,\n",
       " 405,\n",
       " 424,\n",
       " 454,\n",
       " 489,\n",
       " 368,\n",
       " 554,\n",
       " 637,\n",
       " 455,\n",
       " 364,\n",
       " 846,\n",
       " 997,\n",
       " 518,\n",
       " 745,\n",
       " 355,\n",
       " 536,\n",
       " 457,\n",
       " 125,\n",
       " 155,\n",
       " 167,\n",
       " 84,\n",
       " 757,\n",
       " 944,\n",
       " 255,\n",
       " 207,\n",
       " 398,\n",
       " 442,\n",
       " 853,\n",
       " 809,\n",
       " 205,\n",
       " 321,\n",
       " 561,\n",
       " 234,\n",
       " 252,\n",
       " 755,\n",
       " 441,\n",
       " 107,\n",
       " 613,\n",
       " 716,\n",
       " 932,\n",
       " 906,\n",
       " 488,\n",
       " 861,\n",
       " 112,\n",
       " 153,\n",
       " 600,\n",
       " 37,\n",
       " 490,\n",
       " 594,\n",
       " 572,\n",
       " 623,\n",
       " 320,\n",
       " 228,\n",
       " 452,\n",
       " 450,\n",
       " 380,\n",
       " 921,\n",
       " 760,\n",
       " 629,\n",
       " 589,\n",
       " 184,\n",
       " 650,\n",
       " 422,\n",
       " 468,\n",
       " 68,\n",
       " 5,\n",
       " 527,\n",
       " 128,\n",
       " 569,\n",
       " 346,\n",
       " 709,\n",
       " 104,\n",
       " 878,\n",
       " 496,\n",
       " 593,\n",
       " 241,\n",
       " 879,\n",
       " 525,\n",
       " 54,\n",
       " 960,\n",
       " 381,\n",
       " 801,\n",
       " 170,\n",
       " 718,\n",
       " 165,\n",
       " 386,\n",
       " 918,\n",
       " 426,\n",
       " 505,\n",
       " 834,\n",
       " 714,\n",
       " 959,\n",
       " 285,\n",
       " 242,\n",
       " 1,\n",
       " 267,\n",
       " 562,\n",
       " 793,\n",
       " 436,\n",
       " 472,\n",
       " 648,\n",
       " 327,\n",
       " 530,\n",
       " 682,\n",
       " 317,\n",
       " 739,\n",
       " 31,\n",
       " 616,\n",
       " 847,\n",
       " 908,\n",
       " 905,\n",
       " 212,\n",
       " 823,\n",
       " 420,\n",
       " 776,\n",
       " 278,\n",
       " 42,\n",
       " 969,\n",
       " 157,\n",
       " 687,\n",
       " 262,\n",
       " 668,\n",
       " 971,\n",
       " 444,\n",
       " 341,\n",
       " 747,\n",
       " 423,\n",
       " 180,\n",
       " 762,\n",
       " 433,\n",
       " 619,\n",
       " 174,\n",
       " 857,\n",
       " 567,\n",
       " 901,\n",
       " 558,\n",
       " 799,\n",
       " 618,\n",
       " 825,\n",
       " 603,\n",
       " 61,\n",
       " 542,\n",
       " 501,\n",
       " 735,\n",
       " 749,\n",
       " 937,\n",
       " 950,\n",
       " 931,\n",
       " 50,\n",
       " 933,\n",
       " 245,\n",
       " 819,\n",
       " 635,\n",
       " 841,\n",
       " 64,\n",
       " 833,\n",
       " 289,\n",
       " 232,\n",
       " 204,\n",
       " 630,\n",
       " 275,\n",
       " 304,\n",
       " 855,\n",
       " 684,\n",
       " 92,\n",
       " 349,\n",
       " 557,\n",
       " 62,\n",
       " 397,\n",
       " 430,\n",
       " 478,\n",
       " 40,\n",
       " 658,\n",
       " 260,\n",
       " 421,\n",
       " 657,\n",
       " 731,\n",
       " 415,\n",
       " 374,\n",
       " 540,\n",
       " 158,\n",
       " 909,\n",
       " 759,\n",
       " 856,\n",
       " 263,\n",
       " 138,\n",
       " 418,\n",
       " 343,\n",
       " 511,\n",
       " 608,\n",
       " 677,\n",
       " 148,\n",
       " 585,\n",
       " 886,\n",
       " 538,\n",
       " 375,\n",
       " 763,\n",
       " 962,\n",
       " 244,\n",
       " 910,\n",
       " 36,\n",
       " 979,\n",
       " 798,\n",
       " 707,\n",
       " 32,\n",
       " 602,\n",
       " 7,\n",
       " 485,\n",
       " 948,\n",
       " 535,\n",
       " 448,\n",
       " 429,\n",
       " 258,\n",
       " 400,\n",
       " 705,\n",
       " 761,\n",
       " 645,\n",
       " 790,\n",
       " 197,\n",
       " 366,\n",
       " 203,\n",
       " 952,\n",
       " 609,\n",
       " 288,\n",
       " 18]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.indices          # 返回训练集索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在PyTorch中，random_split函数返回的对象（在这个例子中是data_train）有一个indices属性。这个indices属性是一个包含了被选为训练集的数据点的原始索引的列表。这些索引是相对于传递给random_split的原始数据集（在这个例子中是data）的。\n",
    "\n",
    "所以，data_train.indices返回的是一个列表，这个列表包含了被选为训练集的数据点在原始数据集中的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.6023e-01,  1.0791e+00],\n",
       "         [-6.8136e-01,  7.1813e-01],\n",
       "         [ 1.4264e-01,  1.6381e+00],\n",
       "         ...,\n",
       "         [-3.1467e-01, -8.4686e-01],\n",
       "         [-8.5752e-01,  1.8062e-01],\n",
       "         [ 1.1461e-03,  1.9516e+00]]),\n",
       " tensor([[-1.1568e+00],\n",
       "         [-3.0866e+00],\n",
       "         [-2.3423e+00],\n",
       "         [-8.9417e-01],\n",
       "         [-4.0869e+00],\n",
       "         [-2.1211e+00],\n",
       "         [-3.3976e+00],\n",
       "         [ 1.3091e+00],\n",
       "         [-2.6640e+00],\n",
       "         [-1.0844e+00],\n",
       "         [ 6.6663e-01],\n",
       "         [-1.9266e+00],\n",
       "         [-2.4113e-01],\n",
       "         [ 3.5829e-01],\n",
       "         [-2.4472e+00],\n",
       "         [-3.3007e+00],\n",
       "         [-1.8335e+00],\n",
       "         [ 1.8596e+00],\n",
       "         [ 1.9768e+00],\n",
       "         [ 2.9743e+00],\n",
       "         [ 7.4034e-01],\n",
       "         [-1.7798e+00],\n",
       "         [-1.8880e+00],\n",
       "         [-3.2213e+00],\n",
       "         [-4.6567e-01],\n",
       "         [-2.0962e+00],\n",
       "         [ 4.1204e+00],\n",
       "         [-1.5920e+00],\n",
       "         [ 2.8024e+00],\n",
       "         [ 1.7844e+00],\n",
       "         [-4.6246e-01],\n",
       "         [-1.9340e+00],\n",
       "         [ 1.8687e+00],\n",
       "         [-1.8985e+00],\n",
       "         [-6.3805e-01],\n",
       "         [-1.8777e-02],\n",
       "         [-6.3920e+00],\n",
       "         [-5.7081e-01],\n",
       "         [ 1.0613e-01],\n",
       "         [ 7.6660e-03],\n",
       "         [-4.4152e+00],\n",
       "         [-2.0862e-02],\n",
       "         [ 1.7795e+00],\n",
       "         [ 2.1705e-01],\n",
       "         [ 7.8263e-01],\n",
       "         [ 1.3528e+00],\n",
       "         [-4.7447e-01],\n",
       "         [ 7.5620e-01],\n",
       "         [-3.6603e+00],\n",
       "         [-1.2479e+00],\n",
       "         [-3.8407e+00],\n",
       "         [-5.2647e+00],\n",
       "         [-2.7032e+00],\n",
       "         [-3.2397e-01],\n",
       "         [-9.6839e-02],\n",
       "         [ 2.2268e+00],\n",
       "         [-3.5678e+00],\n",
       "         [ 3.7736e+00],\n",
       "         [-2.7139e+00],\n",
       "         [ 4.0645e-01],\n",
       "         [-3.1590e-01],\n",
       "         [ 4.3003e-02],\n",
       "         [ 3.3317e-01],\n",
       "         [-2.7777e-01],\n",
       "         [-2.8233e+00],\n",
       "         [-1.0272e+00],\n",
       "         [-1.6672e+00],\n",
       "         [-3.9140e+00],\n",
       "         [-2.7888e-01],\n",
       "         [-3.6227e+00],\n",
       "         [-1.0069e+00],\n",
       "         [-5.0454e+00],\n",
       "         [ 2.6443e+00],\n",
       "         [-4.5372e-01],\n",
       "         [-2.4683e+00],\n",
       "         [-3.8140e+00],\n",
       "         [-3.8824e+00],\n",
       "         [-2.1733e+00],\n",
       "         [ 2.2604e+00],\n",
       "         [ 1.7096e+00],\n",
       "         [ 9.3038e-01],\n",
       "         [ 1.7743e+00],\n",
       "         [-3.4131e-01],\n",
       "         [ 1.7927e+00],\n",
       "         [ 3.1179e+00],\n",
       "         [-4.9160e-02],\n",
       "         [-1.6831e+00],\n",
       "         [-2.9327e+00],\n",
       "         [ 3.0400e+00],\n",
       "         [ 5.3094e-01],\n",
       "         [-1.9639e+00],\n",
       "         [-1.7639e+00],\n",
       "         [-3.9514e+00],\n",
       "         [-2.7487e+00],\n",
       "         [-3.0067e+00],\n",
       "         [-1.8366e+00],\n",
       "         [-2.5348e+00],\n",
       "         [-2.2025e+00],\n",
       "         [-2.2173e+00],\n",
       "         [-2.4440e+00],\n",
       "         [-3.2071e+00],\n",
       "         [-5.6083e-01],\n",
       "         [ 2.9962e-01],\n",
       "         [-9.3032e-02],\n",
       "         [-2.6298e+00],\n",
       "         [-2.1526e+00],\n",
       "         [ 2.7827e+00],\n",
       "         [ 3.1335e-01],\n",
       "         [-9.8351e-01],\n",
       "         [-4.0591e+00],\n",
       "         [-1.7498e-01],\n",
       "         [-5.2283e+00],\n",
       "         [ 8.6516e-01],\n",
       "         [ 1.3156e+00],\n",
       "         [ 1.6201e+00],\n",
       "         [-1.1404e+00],\n",
       "         [-2.2291e+00],\n",
       "         [-3.2324e+00],\n",
       "         [-1.2714e+00],\n",
       "         [-2.9053e+00],\n",
       "         [ 1.2154e+00],\n",
       "         [ 1.2235e+00],\n",
       "         [-2.8147e+00],\n",
       "         [-2.4026e+00],\n",
       "         [-3.9034e+00],\n",
       "         [-3.4234e+00],\n",
       "         [ 2.4109e+00],\n",
       "         [-2.6521e+00],\n",
       "         [ 1.8954e+00],\n",
       "         [-2.3392e+00],\n",
       "         [-1.9434e+00],\n",
       "         [-1.4806e+00],\n",
       "         [-3.1455e+00],\n",
       "         [-1.4763e+00],\n",
       "         [-2.1466e+00],\n",
       "         [-5.0378e+00],\n",
       "         [-2.5931e+00],\n",
       "         [-1.7816e+00],\n",
       "         [-1.0247e+00],\n",
       "         [ 1.6526e+00],\n",
       "         [ 7.9500e-01],\n",
       "         [-3.2361e+00],\n",
       "         [-1.1998e+00],\n",
       "         [ 2.9056e-01],\n",
       "         [-1.1226e-01],\n",
       "         [-1.7006e+00],\n",
       "         [-4.8231e-01],\n",
       "         [ 5.3207e-01],\n",
       "         [ 4.6475e-01],\n",
       "         [-4.3474e+00],\n",
       "         [ 2.7744e-01],\n",
       "         [ 2.6722e-01],\n",
       "         [ 1.6625e+00],\n",
       "         [-3.2842e+00],\n",
       "         [-3.8581e+00],\n",
       "         [-4.8357e-01],\n",
       "         [-1.1053e+00],\n",
       "         [ 3.7701e+00],\n",
       "         [-9.3779e-01],\n",
       "         [ 2.5976e+00],\n",
       "         [ 4.6459e-01],\n",
       "         [-4.2454e-01],\n",
       "         [-1.0440e+00],\n",
       "         [-1.1759e+00],\n",
       "         [-2.3640e+00],\n",
       "         [ 2.2215e+00],\n",
       "         [-3.9415e+00],\n",
       "         [-3.4218e-01],\n",
       "         [-3.7508e+00],\n",
       "         [-1.2508e+00],\n",
       "         [-3.4113e+00],\n",
       "         [-4.0880e-01],\n",
       "         [-3.5881e+00],\n",
       "         [-8.9306e-01],\n",
       "         [-4.0095e+00],\n",
       "         [-3.1399e+00],\n",
       "         [-1.1214e+00],\n",
       "         [-9.8014e-01],\n",
       "         [-1.8687e+00],\n",
       "         [-1.9624e+00],\n",
       "         [-2.9565e-01],\n",
       "         [ 5.9788e-03],\n",
       "         [-3.4415e+00],\n",
       "         [ 2.4466e+00],\n",
       "         [-2.1551e+00],\n",
       "         [ 2.3706e+00],\n",
       "         [-3.1740e+00],\n",
       "         [-6.4013e-01],\n",
       "         [ 1.5974e+00],\n",
       "         [ 1.0762e+00],\n",
       "         [-1.1899e+00],\n",
       "         [-1.4509e+00],\n",
       "         [ 1.2741e+00],\n",
       "         [ 5.3432e-02],\n",
       "         [-3.6638e+00],\n",
       "         [-4.5289e+00],\n",
       "         [ 2.3475e+00],\n",
       "         [ 7.2824e-01],\n",
       "         [ 4.0519e+00],\n",
       "         [-1.6681e+00],\n",
       "         [ 1.9300e+00],\n",
       "         [ 3.3047e-01],\n",
       "         [ 1.0406e+00],\n",
       "         [-2.5919e+00],\n",
       "         [-2.2502e+00],\n",
       "         [-9.6841e-01],\n",
       "         [-8.8934e-01],\n",
       "         [-6.1728e-01],\n",
       "         [ 4.7005e+00],\n",
       "         [-2.5856e+00],\n",
       "         [ 3.5562e-02],\n",
       "         [ 3.0838e-01],\n",
       "         [-2.8586e+00],\n",
       "         [-1.4850e+00],\n",
       "         [-4.3163e+00],\n",
       "         [ 4.5921e+00],\n",
       "         [ 2.9345e+00],\n",
       "         [ 1.0655e+00],\n",
       "         [ 1.1024e-01],\n",
       "         [-3.9022e+00],\n",
       "         [ 5.2847e-01],\n",
       "         [-3.7599e+00],\n",
       "         [ 6.6455e-02],\n",
       "         [-3.8568e+00],\n",
       "         [-8.7084e-01],\n",
       "         [ 1.0960e+00],\n",
       "         [-1.9007e+00],\n",
       "         [-7.0628e-01],\n",
       "         [-7.3902e-01],\n",
       "         [-1.5109e+00],\n",
       "         [-4.6039e-01],\n",
       "         [ 5.2202e-01],\n",
       "         [ 1.9190e+00],\n",
       "         [-3.8052e+00],\n",
       "         [-3.6266e+00],\n",
       "         [ 3.0378e+00],\n",
       "         [ 3.3735e+00],\n",
       "         [-4.6385e+00],\n",
       "         [-2.9822e+00],\n",
       "         [ 1.2221e+00],\n",
       "         [-2.5407e+00],\n",
       "         [-9.6676e-01],\n",
       "         [ 1.2557e+00],\n",
       "         [ 7.1771e-01],\n",
       "         [ 1.0422e+00],\n",
       "         [-2.3030e+00],\n",
       "         [ 3.0559e+00],\n",
       "         [-1.9077e+00],\n",
       "         [-2.5983e+00],\n",
       "         [-2.7338e+00],\n",
       "         [-3.2253e+00],\n",
       "         [-1.3966e+00],\n",
       "         [-1.3800e+00],\n",
       "         [-2.2374e+00],\n",
       "         [-7.3307e-01],\n",
       "         [ 6.4839e-02],\n",
       "         [-1.5860e+00],\n",
       "         [ 1.8960e-01],\n",
       "         [ 2.4645e-01],\n",
       "         [-1.8262e+00],\n",
       "         [-1.0031e+00],\n",
       "         [-1.6514e+00],\n",
       "         [-1.1678e+00],\n",
       "         [ 1.3634e+00],\n",
       "         [-2.6713e+00],\n",
       "         [-5.3295e+00],\n",
       "         [-3.5104e+00],\n",
       "         [ 6.4273e-01],\n",
       "         [-1.2252e+00],\n",
       "         [-5.3288e+00],\n",
       "         [-1.3151e+00],\n",
       "         [-4.3470e+00],\n",
       "         [-3.0972e+00],\n",
       "         [ 7.5967e-01],\n",
       "         [ 1.3790e+00],\n",
       "         [-3.6997e+00],\n",
       "         [ 8.6652e-02],\n",
       "         [ 1.2605e+00],\n",
       "         [ 3.6070e+00],\n",
       "         [-8.3090e-01],\n",
       "         [ 2.3512e-01],\n",
       "         [-1.8381e+00],\n",
       "         [-4.3527e+00],\n",
       "         [-4.1996e+00],\n",
       "         [-1.5995e+00],\n",
       "         [-8.0388e-01],\n",
       "         [-5.7159e+00],\n",
       "         [-1.5099e+00],\n",
       "         [-4.5462e+00],\n",
       "         [-3.5241e+00],\n",
       "         [ 1.8400e+00],\n",
       "         [ 6.4239e-01],\n",
       "         [ 2.9962e+00],\n",
       "         [ 2.6578e-02],\n",
       "         [-2.3040e+00],\n",
       "         [-3.2355e+00],\n",
       "         [-3.4507e-01],\n",
       "         [-4.0082e+00],\n",
       "         [-2.8007e+00],\n",
       "         [ 1.9640e+00],\n",
       "         [-1.0284e+00],\n",
       "         [-3.5432e-01],\n",
       "         [-1.1965e+00],\n",
       "         [ 6.7815e-01],\n",
       "         [-4.8404e+00],\n",
       "         [ 2.7012e-01],\n",
       "         [-2.5042e+00],\n",
       "         [-2.2780e+00],\n",
       "         [-4.8930e+00],\n",
       "         [-2.7111e+00],\n",
       "         [-4.9964e+00],\n",
       "         [-1.5400e+00],\n",
       "         [-6.5237e-01],\n",
       "         [-5.4286e-01],\n",
       "         [-4.8848e+00],\n",
       "         [ 2.3164e+00],\n",
       "         [-1.1335e+00],\n",
       "         [-2.0443e+00],\n",
       "         [-1.6460e+00],\n",
       "         [-1.7519e+00],\n",
       "         [-1.1080e+00],\n",
       "         [ 4.2860e-01],\n",
       "         [-1.8422e+00],\n",
       "         [ 2.4319e+00],\n",
       "         [ 5.8448e-02],\n",
       "         [-3.2735e+00],\n",
       "         [-3.7668e+00],\n",
       "         [ 8.7762e-01],\n",
       "         [-1.2056e+00],\n",
       "         [-2.9531e+00],\n",
       "         [-2.7390e+00],\n",
       "         [-1.1665e+00],\n",
       "         [ 1.8161e-01],\n",
       "         [-4.3883e+00],\n",
       "         [-2.2740e+00],\n",
       "         [-5.1317e+00],\n",
       "         [-4.5061e+00],\n",
       "         [ 2.9849e+00],\n",
       "         [ 9.4310e-01],\n",
       "         [ 1.4831e+00],\n",
       "         [-2.7085e+00],\n",
       "         [ 1.0631e+00],\n",
       "         [-2.2579e+00],\n",
       "         [-3.1599e+00],\n",
       "         [ 1.9713e+00],\n",
       "         [-2.7094e+00],\n",
       "         [ 2.3774e+00],\n",
       "         [ 3.5040e+00],\n",
       "         [ 5.6411e-01],\n",
       "         [-2.8741e+00],\n",
       "         [-1.5556e+00],\n",
       "         [-1.7635e+00],\n",
       "         [-2.5898e+00],\n",
       "         [-2.4402e+00],\n",
       "         [ 1.3936e+00],\n",
       "         [-3.8252e+00],\n",
       "         [-1.0798e+00],\n",
       "         [-8.5362e-01],\n",
       "         [ 5.0864e-01],\n",
       "         [ 5.8377e-01],\n",
       "         [-3.1424e+00],\n",
       "         [-2.7692e+00],\n",
       "         [ 8.2182e-01],\n",
       "         [ 1.1146e+00],\n",
       "         [ 2.1009e-01],\n",
       "         [ 4.5123e-01],\n",
       "         [-1.1101e+00],\n",
       "         [-3.4217e+00],\n",
       "         [-4.9161e-02],\n",
       "         [-2.5590e+00],\n",
       "         [-4.1151e-01],\n",
       "         [-8.5222e-02],\n",
       "         [-8.3988e-01],\n",
       "         [-2.0050e+00],\n",
       "         [-1.8023e+00],\n",
       "         [-2.8824e+00],\n",
       "         [ 7.3067e-01],\n",
       "         [-1.0979e+00],\n",
       "         [ 1.2153e+00],\n",
       "         [-2.8868e+00],\n",
       "         [-1.1268e+00],\n",
       "         [ 5.6152e-01],\n",
       "         [-4.9421e+00],\n",
       "         [ 3.7279e-01],\n",
       "         [ 3.0437e+00],\n",
       "         [-1.7681e-01],\n",
       "         [-1.3301e+00],\n",
       "         [ 2.3940e+00],\n",
       "         [-4.3763e-01],\n",
       "         [ 1.3866e+00],\n",
       "         [-1.5757e+00],\n",
       "         [-2.3797e+00],\n",
       "         [ 1.1477e+00],\n",
       "         [-2.9241e+00],\n",
       "         [ 3.9246e+00],\n",
       "         [-1.1463e+00],\n",
       "         [-1.5067e+00],\n",
       "         [-6.9769e-01],\n",
       "         [ 1.2554e+00],\n",
       "         [ 7.8504e-01],\n",
       "         [ 1.0164e+00],\n",
       "         [ 2.5054e+00],\n",
       "         [-1.6145e+00],\n",
       "         [-1.2958e+00],\n",
       "         [-2.9091e+00],\n",
       "         [-2.8263e+00],\n",
       "         [-1.4122e+00],\n",
       "         [-4.5224e+00],\n",
       "         [-3.6750e+00],\n",
       "         [-2.5093e+00],\n",
       "         [ 4.4807e+00],\n",
       "         [-3.9053e+00],\n",
       "         [ 9.5657e-01],\n",
       "         [ 1.0650e+00],\n",
       "         [ 4.0314e+00],\n",
       "         [-2.6788e+00],\n",
       "         [-2.0872e+00],\n",
       "         [-6.7043e-01],\n",
       "         [-5.9630e-02],\n",
       "         [-4.4215e+00],\n",
       "         [-1.5890e+00],\n",
       "         [-5.6710e-01],\n",
       "         [ 6.3989e-01],\n",
       "         [-5.6301e+00],\n",
       "         [-2.1385e+00],\n",
       "         [ 4.6419e-01],\n",
       "         [-1.2894e+00],\n",
       "         [-4.3773e-01],\n",
       "         [-1.3643e+00],\n",
       "         [ 9.5469e-02],\n",
       "         [ 2.3865e+00],\n",
       "         [ 2.8780e-01],\n",
       "         [-2.5712e-01],\n",
       "         [-9.7778e-01],\n",
       "         [-2.5436e+00],\n",
       "         [-1.3772e+00],\n",
       "         [ 3.7764e-02],\n",
       "         [-1.9328e+00],\n",
       "         [ 6.8403e-02],\n",
       "         [ 3.1355e+00],\n",
       "         [ 3.8829e-01],\n",
       "         [-1.3409e-01],\n",
       "         [ 1.0696e-01],\n",
       "         [-3.8459e+00],\n",
       "         [-4.0485e+00],\n",
       "         [ 6.6377e-02],\n",
       "         [-2.4850e+00],\n",
       "         [-1.1079e-01],\n",
       "         [-1.5270e+00],\n",
       "         [-8.8267e-01],\n",
       "         [-5.0184e+00],\n",
       "         [ 3.5821e+00],\n",
       "         [-2.4345e+00],\n",
       "         [ 3.8305e-01],\n",
       "         [-4.0053e-01],\n",
       "         [-4.3509e+00],\n",
       "         [-2.1464e+00],\n",
       "         [ 7.1958e-01],\n",
       "         [ 1.1007e+00],\n",
       "         [-1.5682e+00],\n",
       "         [-2.0103e+00],\n",
       "         [-2.9322e+00],\n",
       "         [-2.2928e-01],\n",
       "         [-4.1973e-01],\n",
       "         [-3.5979e+00],\n",
       "         [-4.8675e+00],\n",
       "         [ 1.9018e+00],\n",
       "         [-2.7835e-01],\n",
       "         [ 2.7043e+00],\n",
       "         [-4.0631e+00],\n",
       "         [ 7.9524e-01],\n",
       "         [-2.4040e+00],\n",
       "         [-5.9183e+00],\n",
       "         [-2.2535e+00],\n",
       "         [-1.5077e+00],\n",
       "         [ 4.3234e-01],\n",
       "         [ 3.0031e-01],\n",
       "         [-1.2805e+00],\n",
       "         [ 2.7171e+00],\n",
       "         [-5.4644e-01],\n",
       "         [ 1.2576e+00],\n",
       "         [ 4.6420e-01],\n",
       "         [-6.9799e-01],\n",
       "         [ 2.4725e+00],\n",
       "         [-6.4577e-01],\n",
       "         [-1.4449e+00],\n",
       "         [-3.3037e+00],\n",
       "         [ 1.0775e+00],\n",
       "         [-2.7165e+00],\n",
       "         [-8.8164e-01],\n",
       "         [-4.8854e+00],\n",
       "         [-9.1630e-01],\n",
       "         [ 1.5884e+00],\n",
       "         [-2.6434e+00],\n",
       "         [ 1.7851e+00],\n",
       "         [ 2.1585e+00],\n",
       "         [-2.4018e+00],\n",
       "         [ 1.5739e+00],\n",
       "         [ 2.6404e+00],\n",
       "         [-2.1935e+00],\n",
       "         [ 1.9888e+00],\n",
       "         [ 1.1701e-01],\n",
       "         [-2.2419e+00],\n",
       "         [ 1.7155e-01],\n",
       "         [ 4.8598e-01],\n",
       "         [ 9.9586e-02],\n",
       "         [ 5.7648e-02],\n",
       "         [-2.9960e+00],\n",
       "         [-1.7532e+00],\n",
       "         [-4.4404e+00],\n",
       "         [ 3.5461e+00],\n",
       "         [-2.6234e-01],\n",
       "         [-4.2718e+00],\n",
       "         [ 4.3389e-01],\n",
       "         [-4.9715e+00],\n",
       "         [-6.6409e-01],\n",
       "         [-4.2423e-01],\n",
       "         [-1.7507e+00],\n",
       "         [-5.7819e-02],\n",
       "         [ 9.2053e-01],\n",
       "         [-2.0058e+00],\n",
       "         [-3.3427e+00],\n",
       "         [-2.1366e-01],\n",
       "         [-2.6144e+00],\n",
       "         [-2.3149e+00],\n",
       "         [ 1.5305e+00],\n",
       "         [-2.8329e+00],\n",
       "         [-3.2875e+00],\n",
       "         [ 2.1364e+00],\n",
       "         [-1.4868e+00],\n",
       "         [-1.4777e+00],\n",
       "         [-2.5323e+00],\n",
       "         [-1.2863e+00],\n",
       "         [-2.3277e+00],\n",
       "         [-3.4384e+00],\n",
       "         [-1.3316e+00],\n",
       "         [ 1.0322e+00],\n",
       "         [ 1.0307e+00],\n",
       "         [ 8.7586e-01],\n",
       "         [-4.1348e-01],\n",
       "         [-3.4506e+00],\n",
       "         [-3.5582e+00],\n",
       "         [ 2.3613e-01],\n",
       "         [ 3.4006e+00],\n",
       "         [-2.0820e+00],\n",
       "         [ 6.0619e-01],\n",
       "         [-4.2063e+00],\n",
       "         [-1.4862e+00],\n",
       "         [-9.9961e-01],\n",
       "         [-3.3586e+00],\n",
       "         [-1.9415e+00],\n",
       "         [ 8.3184e-01],\n",
       "         [ 1.8637e+00],\n",
       "         [-1.8449e-02],\n",
       "         [-3.7364e+00],\n",
       "         [-3.8101e+00],\n",
       "         [ 9.7085e-01],\n",
       "         [-1.4773e+00],\n",
       "         [-2.2383e-01],\n",
       "         [ 2.9534e+00],\n",
       "         [-3.0149e+00],\n",
       "         [-1.0564e+00],\n",
       "         [-2.4308e+00],\n",
       "         [-1.2062e+00],\n",
       "         [-2.2226e+00],\n",
       "         [-3.2171e-01],\n",
       "         [-2.0294e+00],\n",
       "         [-4.3153e+00],\n",
       "         [-1.5973e+00],\n",
       "         [ 2.9241e+00],\n",
       "         [-2.1903e+00],\n",
       "         [-6.2520e+00],\n",
       "         [-3.0536e+00],\n",
       "         [-5.3954e+00],\n",
       "         [ 1.6568e+00],\n",
       "         [-8.5386e-02],\n",
       "         [-1.2179e+00],\n",
       "         [ 7.0665e-01],\n",
       "         [ 1.9098e+00],\n",
       "         [-4.4058e+00],\n",
       "         [-9.1052e-01],\n",
       "         [-3.1831e+00],\n",
       "         [-3.3513e+00],\n",
       "         [ 2.7919e+00],\n",
       "         [-3.7264e+00],\n",
       "         [ 1.7583e+00],\n",
       "         [-8.6748e-01],\n",
       "         [ 2.4584e+00],\n",
       "         [ 2.4960e+00],\n",
       "         [-4.5319e+00],\n",
       "         [-2.2479e-01],\n",
       "         [-1.9826e+00],\n",
       "         [ 3.7678e+00],\n",
       "         [-2.6815e+00],\n",
       "         [ 6.3449e-01],\n",
       "         [ 3.6650e-01],\n",
       "         [-1.7483e+00],\n",
       "         [-7.0109e-01],\n",
       "         [-3.4861e+00],\n",
       "         [ 4.8403e-01],\n",
       "         [ 2.2316e+00],\n",
       "         [-2.5161e+00],\n",
       "         [-1.0094e+00],\n",
       "         [-1.3577e+00],\n",
       "         [ 5.4534e-02],\n",
       "         [-2.8333e-01],\n",
       "         [ 2.0357e+00],\n",
       "         [-1.0392e+00],\n",
       "         [-2.7778e-01],\n",
       "         [-5.5013e-02],\n",
       "         [-1.0359e+00],\n",
       "         [ 1.2757e+00],\n",
       "         [-6.9061e-01],\n",
       "         [ 5.1659e-01],\n",
       "         [-3.1793e+00],\n",
       "         [-1.8923e+00],\n",
       "         [-1.6419e+00],\n",
       "         [ 1.6355e+00],\n",
       "         [-3.5108e+00],\n",
       "         [ 2.2125e-01],\n",
       "         [-1.9656e+00],\n",
       "         [ 3.6113e+00],\n",
       "         [ 2.4626e+00],\n",
       "         [ 6.4790e-01],\n",
       "         [-1.4455e+00],\n",
       "         [-2.2006e+00],\n",
       "         [-2.6441e+00],\n",
       "         [ 1.0327e+00],\n",
       "         [-2.6566e+00],\n",
       "         [-4.8147e-01],\n",
       "         [ 3.1867e+00],\n",
       "         [ 1.2911e+00],\n",
       "         [-1.6059e+00],\n",
       "         [-2.5209e+00],\n",
       "         [-1.9165e+00],\n",
       "         [-1.6787e+00],\n",
       "         [-2.2704e+00],\n",
       "         [-5.0917e-01],\n",
       "         [-3.6189e-01],\n",
       "         [-3.4282e+00],\n",
       "         [-3.7201e+00],\n",
       "         [ 1.3772e+00],\n",
       "         [ 4.4911e+00],\n",
       "         [-6.8271e-01],\n",
       "         [-1.9075e+00],\n",
       "         [-1.6388e+00],\n",
       "         [-1.0464e+00],\n",
       "         [ 2.4634e-01],\n",
       "         [-2.5852e+00],\n",
       "         [-1.4757e+00],\n",
       "         [ 1.9718e-01],\n",
       "         [ 2.6737e-01],\n",
       "         [-5.9062e-01],\n",
       "         [-1.1967e+00],\n",
       "         [-1.5097e+00],\n",
       "         [-4.0305e-01],\n",
       "         [-2.3045e+00],\n",
       "         [-4.9829e-01],\n",
       "         [-3.4157e-01],\n",
       "         [-8.7944e-01],\n",
       "         [-7.1748e-03],\n",
       "         [-5.2002e-01],\n",
       "         [-4.2296e+00],\n",
       "         [-3.9709e+00],\n",
       "         [-2.7010e+00],\n",
       "         [ 1.9738e+00],\n",
       "         [-7.8994e-01],\n",
       "         [-7.4859e-01],\n",
       "         [-2.4811e+00],\n",
       "         [ 1.0472e+00],\n",
       "         [ 2.0516e+00],\n",
       "         [ 3.4269e+00],\n",
       "         [-3.5160e+00],\n",
       "         [-2.2645e+00],\n",
       "         [-1.2515e+00],\n",
       "         [ 3.2691e+00],\n",
       "         [ 6.7012e+00],\n",
       "         [ 2.9995e+00],\n",
       "         [ 1.7198e+00],\n",
       "         [-2.3551e+00],\n",
       "         [-1.7956e+00],\n",
       "         [-3.6121e+00],\n",
       "         [-3.3688e+00],\n",
       "         [-2.9421e-01],\n",
       "         [ 2.0488e+00],\n",
       "         [-1.4491e+00],\n",
       "         [-6.4332e-01],\n",
       "         [ 1.6306e-01],\n",
       "         [-3.6117e+00],\n",
       "         [-7.3539e-01],\n",
       "         [ 2.0556e-01],\n",
       "         [-4.8202e+00],\n",
       "         [-1.3490e+00],\n",
       "         [ 1.1489e+00],\n",
       "         [ 1.2204e+00],\n",
       "         [-2.2209e+00],\n",
       "         [-4.1402e+00],\n",
       "         [-7.7996e-01],\n",
       "         [-2.8970e+00],\n",
       "         [-2.9473e+00]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data_train.indices]        # 返回训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.6023e-01,  1.0791e+00],\n",
       "        [-6.8136e-01,  7.1813e-01],\n",
       "        [ 1.4264e-01,  1.6381e+00],\n",
       "        ...,\n",
       "        [-3.1467e-01, -8.4686e-01],\n",
       "        [-8.5752e-01,  1.8062e-01],\n",
       "        [ 1.1461e-03,  1.9516e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data_train.indices][0]     # 返回训练集的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.4242e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算训练集的MSE\n",
    "F.mse_loss(LR_model(data[data_train.indices][0]), data[data_train.indices][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.1282e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算测试集上的MSE\n",
    "F.mse_loss(LR_model(data[data_test.indices][0]), data[data_test.indices][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.4242e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.1282e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute MSE for training set\n",
    "train_features, train_labels = data[data_train.indices]\n",
    "train_predictions = LR_model(train_features)\n",
    "train_loss = F.mse_loss(train_predictions, train_labels)\n",
    "print(train_loss)\n",
    "# Compute MSE for test set\n",
    "test_features, test_labels = data[data_test.indices]\n",
    "test_predictions = LR_model(test_features)\n",
    "test_loss = F.mse_loss(test_predictions, test_labels)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，即完成了整个从数据集切分到模型训练，再到查看模型在不同训练集上表现的全过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1.3.3 实用函数补充\n",
    "\n",
    "结合上述过程，我们可以补充一些实用函数，方便简化后续建模流程。\n",
    "\n",
    "* 数据封装/切分/加载函数\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该函数可以直接将输入的特征和标签直接进行封装/切分和加载。该函数可以直接处理此前定义的数据生成器创建的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_loader(features, labels, batch_size = 10, rate = 0.7):\n",
    "    \"\"\"数据封装，切分，和加载函数：\n",
    "    \n",
    "    param features: 输入的特征\n",
    "    param labels: 数据集标签张量\n",
    "    param batch_size: 数据加载时的每一个小批数据量\n",
    "    param rate: 训练集数据占比\n",
    "    return: 加载好的训练集和测试集\n",
    "    \"\"\"\n",
    "\n",
    "    data = GenData(features, labels)\n",
    "    num_train = int(data.lens * 0.7)\n",
    "    num_test = data.lens - num_train\n",
    "    data_train, data_test = random_split(data, [num_train, num_test])\n",
    "    train_loader = DataLoader(data_train, batch_size= batch_size, shuffle= True)\n",
    "    test_loader = DataLoader(data_test, batch_size = batch_size, shuffle= False)\n",
    "    return (train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试函数性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "torch.manual_seed(420)\n",
    "\n",
    "# 创建数据集\n",
    "features, labels = tensorGenReg()\n",
    "features = features[:, : -1]\n",
    "\n",
    "# 进行数据加载\n",
    "train_loader, test_loader = split_loader(features= features, labels= labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.4463, -0.6221]), tensor([-3.2863]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看第一条训练集数据\n",
    "train_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset[:][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 模型训练函数\n",
    "\n",
    "模型训练函数并不是新的函数，此处正式对其进行定义并写入自定义模块中，方便后续调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, criterion, optimizer, batchdata, epochs = 3, cla = False):\n",
    "    \"\"\"模型训练函数\n",
    "    \n",
    "    param net: 待训练模型\n",
    "    param criterion: 损失函数\n",
    "    param optimizer: 优化算法\n",
    "    param batchdata: 训练数据集\n",
    "    param cla: 是否是分类问题\n",
    "    param epochs: 遍历数据次数\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in batchdata:\n",
    "            if cla == True:\n",
    "                y = y.flatten().long()      # 如果是分类问题，需要对y进行整数转化\n",
    "            yhat = net.forward(X)\n",
    "            loss = criterion(yhat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MSE计算函数\n",
    "\n",
    "接下来，我们借助F.mse_loss，定义一个可以直接根据模型输出结果和加载后的数据计算MSE的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_cal(data_loader, net):\n",
    "    \"\"\" mse计算函数\n",
    "    \n",
    "    param data_loader: 加载好的数据\n",
    "    param net: 模型\n",
    "    return: 根据输入的数据, 输出其MSE计算结果\n",
    "    \"\"\"\n",
    "    data = data_loader.dataset      # 还原Dataset类\n",
    "    X = data[:][0]                  # 还原数据的特征\n",
    "    y = data[:][1]                  # 还原数据的标签\n",
    "    yhat = net(X)\n",
    "    return F.mse_loss(yhat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4463, -0.6221],\n",
       "        [-0.4742, -0.2939],\n",
       "        [ 1.9870,  0.1949],\n",
       "        ...,\n",
       "        [-1.6366, -2.1399],\n",
       "        [-1.8178, -1.4618],\n",
       "        [ 0.2646,  2.3555]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，测试函数性能。借助上述建模实验中构建的回归模型，测试函数是否顺利执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "torch.manual_seed(420)\n",
    "\n",
    "# 实例化模型\n",
    "LR_model = LR()\n",
    "\n",
    "# 初始化核心参数\n",
    "batch_size = 10         # 小批的数量\n",
    "lr = 0.03               # 学习率\n",
    "num_epochs = 3          # 训练过程遍历多少次数据\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 定义优化算法\n",
    "optimizer = optim.SGD(LR_model.parameters(), lr= lr)\n",
    "\n",
    "# 训练模型\n",
    "fit(net= LR_model,\n",
    "    criterion= criterion,\n",
    "    optimizer= optimizer,\n",
    "    batchdata= train_loader,\n",
    "    epochs= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_cal(train_loader, LR_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.9602e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_cal(test_loader, LR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 准确率计算函数\n",
    "\n",
    "类似的，定义一个分类问题的准确率计算函数，同样要求输入是加载后的数据集和训练完成的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cal(data_loader, net):\n",
    "    \"\"\" 准确率\n",
    "    data_loader: 加载好的数据\n",
    "    net: 模型\n",
    "    return: 根据输入的数据，输出其准确率计算结果\n",
    "    \"\"\"\n",
    "\n",
    "    data = data_loader.dataset      # 还原Dataset类\n",
    "    x = data[:][0]                  # 还原数据的特征\n",
    "    y = data[:][1]                  # 还原数据的标签\n",
    "    zhat = net(x)                   # 默认是分类问题，且输出结果是未经过softmax转化的结果\n",
    "    soft_z = F.softmax(zhat, 1)\n",
    "    acc_bool = torch.argmax(soft_z, 1).flatten() == y.flatten()\n",
    "    acc = torch.mean(acc_bool.float())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(9).reshape(3, 3).float()\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，测试函数性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "torch.manual_seed(420)\n",
    "\n",
    "# 创建分类数据集\n",
    "features, labels = tensorGenCla()\n",
    "\n",
    "# 进行数据加载\n",
    "train_loader, test_loader = split_loader(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmaxR(nn.Module):\n",
    "    def __init__(self, in_features= 2, out_features = 3, bias = False) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "# 实例化模型\n",
    "softmax_model = softmaxR()\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化算法\n",
    "optimizer = optim.SGD(softmax_model.parameters(), lr= lr)\n",
    "\n",
    "# 执行模型训练\n",
    "fit(net= softmax_model,\n",
    "    criterion= criterion,\n",
    "    optimizer= optimizer,\n",
    "    batchdata= train_loader,\n",
    "    epochs= num_epochs,\n",
    "    cla = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8743)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cal(train_loader, softmax_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8733)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cal(test_loader, softmax_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
